{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forestfire=pd.read_csv(\"D:/Work/Data Science and Analyst Course/ExcelR/Data Science/Assignments/16_Neural Networks/forestfires.csv\")\n",
    "df_forestfire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month            0\n",
       "day              0\n",
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "dayfri           0\n",
       "daymon           0\n",
       "daysat           0\n",
       "daysun           0\n",
       "daythu           0\n",
       "daytue           0\n",
       "daywed           0\n",
       "monthapr         0\n",
       "monthaug         0\n",
       "monthdec         0\n",
       "monthfeb         0\n",
       "monthjan         0\n",
       "monthjul         0\n",
       "monthjun         0\n",
       "monthmar         0\n",
       "monthmay         0\n",
       "monthnov         0\n",
       "monthoct         0\n",
       "monthsep         0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Problem statement: PREDICT THE BURNED AREA OF FOREST FIRES WITH NEURAL NETWORKS\n",
    "\n",
    "df_forestfire.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forestfire.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain         area      dayfri  ...    monthdec  \\\n",
       "count  517.000000  517.000000   517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    12.847292    0.164410  ...    0.017408   \n",
       "std      1.791653    0.295959    63.655818    0.371006  ...    0.130913   \n",
       "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000     0.520000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000     6.570000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthfeb    monthjan    monthjul    monthjun    monthmar    monthmay  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.038685    0.003868    0.061896    0.032882    0.104449    0.003868   \n",
       "std      0.193029    0.062137    0.241199    0.178500    0.306138    0.062137   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthnov    monthoct    monthsep  \n",
       "count  517.000000  517.000000  517.000000  \n",
       "mean     0.001934    0.029014    0.332689  \n",
       "std      0.043980    0.168007    0.471632  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forestfire.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Diving target and features\n",
    "X=df_forestfire.iloc[:,:-1]\n",
    "Y=df_forestfire.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>144</td>\n",
       "      <td>42</td>\n",
       "      <td>85</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>156</td>\n",
       "      <td>42</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>68</td>\n",
       "      <td>30</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>172</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>123</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>116</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>168</td>\n",
       "      <td>122</td>\n",
       "      <td>80</td>\n",
       "      <td>156</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  day  FFMC  DMC   DC  ISI  temp  RH  wind  rain  ...  monthdec  \\\n",
       "0        7    0    28   37   41   29    12  34    14     0  ...         0   \n",
       "1       10    5    56   49  144   42    85  16     1     0  ...         0   \n",
       "2       10    2    56   56  156   42    55  16     2     0  ...         0   \n",
       "3        7    0    67   48   33   64    13  72     8     1  ...         0   \n",
       "4        7    3    46   66   46   68    30  73     3     0  ...         0   \n",
       "..     ...  ...   ...  ...  ...  ...   ...  ..   ...   ...  ...       ...   \n",
       "512      1    3     9   71  141    7   172  15     5     0  ...         0   \n",
       "513      1    3     9   71  141    7   123  54    12     0  ...         0   \n",
       "514      1    3     9   71  141    7   116  53    14     0  ...         0   \n",
       "515      1    2    92  168  122   80   156  25     8     0  ...         0   \n",
       "516      9    5     7    2   48    4    34  14     9     0  ...         0   \n",
       "\n",
       "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "0           0         0         0         0         1         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         1         0         0   \n",
       "4           0         0         0         0         1         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         1   \n",
       "\n",
       "     monthoct  monthsep  \n",
       "0           0         0  \n",
       "1           1         0  \n",
       "2           1         0  \n",
       "3           0         0  \n",
       "4           0         0  \n",
       "..        ...       ...  \n",
       "512         0         0  \n",
       "513         0         0  \n",
       "514         0         0  \n",
       "515         0         0  \n",
       "516         0         0  \n",
       "\n",
       "[517 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder_x=LabelEncoder()\n",
    "X=X.apply(LabelEncoder().fit_transform)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     size_category\n",
       "0                1\n",
       "1                1\n",
       "2                1\n",
       "3                1\n",
       "4                1\n",
       "..             ...\n",
       "512              0\n",
       "513              0\n",
       "514              0\n",
       "515              1\n",
       "516              1\n",
       "\n",
       "[517 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "label_encoder_y = LabelEncoder()\n",
    "Y = Y.apply(LabelEncoder().fit_transform)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=30, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "35/35 [==============================] - 2s 13ms/step - loss: 0.6379 - accuracy: 0.7254 - val_loss: 0.5696 - val_accuracy: 0.6901\n",
      "Epoch 2/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8410 - val_loss: 0.3702 - val_accuracy: 0.8129\n",
      "Epoch 3/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1958 - accuracy: 0.9509 - val_loss: 0.1913 - val_accuracy: 0.9064\n",
      "Epoch 4/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1011 - accuracy: 0.9711 - val_loss: 0.1518 - val_accuracy: 0.9357\n",
      "Epoch 5/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9740 - val_loss: 0.1348 - val_accuracy: 0.9474\n",
      "Epoch 6/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9740 - val_loss: 0.2392 - val_accuracy: 0.8830\n",
      "Epoch 7/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9769 - val_loss: 0.1918 - val_accuracy: 0.9006\n",
      "Epoch 8/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9855 - val_loss: 0.1197 - val_accuracy: 0.9415\n",
      "Epoch 9/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9769 - val_loss: 0.1760 - val_accuracy: 0.9181\n",
      "Epoch 10/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9769 - val_loss: 0.1668 - val_accuracy: 0.9240\n",
      "Epoch 11/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9769 - val_loss: 0.2852 - val_accuracy: 0.8830\n",
      "Epoch 12/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0538 - accuracy: 0.9798 - val_loss: 0.1214 - val_accuracy: 0.9532\n",
      "Epoch 13/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9711 - val_loss: 0.1211 - val_accuracy: 0.9474\n",
      "Epoch 14/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.9740 - val_loss: 0.1534 - val_accuracy: 0.9298\n",
      "Epoch 15/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9798 - val_loss: 0.1590 - val_accuracy: 0.9240\n",
      "Epoch 16/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0482 - accuracy: 0.9827 - val_loss: 0.1276 - val_accuracy: 0.9474\n",
      "Epoch 17/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9827 - val_loss: 0.1259 - val_accuracy: 0.9474\n",
      "Epoch 18/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9711 - val_loss: 0.1292 - val_accuracy: 0.9415\n",
      "Epoch 19/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9798 - val_loss: 0.1313 - val_accuracy: 0.9415\n",
      "Epoch 20/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9827 - val_loss: 0.1220 - val_accuracy: 0.9415\n",
      "Epoch 21/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9798 - val_loss: 0.1223 - val_accuracy: 0.9357\n",
      "Epoch 22/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9798 - val_loss: 0.1099 - val_accuracy: 0.9415\n",
      "Epoch 23/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9769 - val_loss: 0.1176 - val_accuracy: 0.9357\n",
      "Epoch 24/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9855 - val_loss: 0.2375 - val_accuracy: 0.9064\n",
      "Epoch 25/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9827 - val_loss: 0.1493 - val_accuracy: 0.9415\n",
      "Epoch 26/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9798 - val_loss: 0.1388 - val_accuracy: 0.9415\n",
      "Epoch 27/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9798 - val_loss: 0.1302 - val_accuracy: 0.9357\n",
      "Epoch 28/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 0.9827 - val_loss: 0.1677 - val_accuracy: 0.9298\n",
      "Epoch 29/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9913 - val_loss: 0.1187 - val_accuracy: 0.9357\n",
      "Epoch 30/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9740 - val_loss: 0.1664 - val_accuracy: 0.9357\n",
      "Epoch 31/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9855 - val_loss: 0.1646 - val_accuracy: 0.9357\n",
      "Epoch 32/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.9855 - val_loss: 0.1306 - val_accuracy: 0.9357\n",
      "Epoch 33/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9740 - val_loss: 0.1284 - val_accuracy: 0.9357\n",
      "Epoch 34/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9855 - val_loss: 0.1986 - val_accuracy: 0.9240\n",
      "Epoch 35/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9827 - val_loss: 0.1817 - val_accuracy: 0.9357\n",
      "Epoch 36/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0336 - accuracy: 0.9827 - val_loss: 0.1641 - val_accuracy: 0.9357\n",
      "Epoch 37/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.9827 - val_loss: 0.2130 - val_accuracy: 0.9240\n",
      "Epoch 38/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.9855 - val_loss: 0.1338 - val_accuracy: 0.9357\n",
      "Epoch 39/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9855 - val_loss: 0.1377 - val_accuracy: 0.9357\n",
      "Epoch 40/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 0.9855 - val_loss: 0.1355 - val_accuracy: 0.9357\n",
      "Epoch 41/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9827 - val_loss: 0.1590 - val_accuracy: 0.9357\n",
      "Epoch 42/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9827 - val_loss: 0.2319 - val_accuracy: 0.9240\n",
      "Epoch 43/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9827 - val_loss: 0.2605 - val_accuracy: 0.9357\n",
      "Epoch 44/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9884 - val_loss: 0.1810 - val_accuracy: 0.9474\n",
      "Epoch 45/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.9798 - val_loss: 0.2030 - val_accuracy: 0.9298\n",
      "Epoch 46/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 0.9855 - val_loss: 0.1880 - val_accuracy: 0.9415\n",
      "Epoch 47/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 0.9855 - val_loss: 0.2527 - val_accuracy: 0.9357\n",
      "Epoch 48/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9884 - val_loss: 0.2622 - val_accuracy: 0.9357\n",
      "Epoch 49/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9855 - val_loss: 0.2966 - val_accuracy: 0.9298\n",
      "Epoch 50/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9884 - val_loss: 0.1518 - val_accuracy: 0.9298\n",
      "Epoch 51/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9855 - val_loss: 0.1786 - val_accuracy: 0.9415\n",
      "Epoch 52/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9884 - val_loss: 0.1796 - val_accuracy: 0.9415\n",
      "Epoch 53/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.9913 - val_loss: 0.1569 - val_accuracy: 0.9357\n",
      "Epoch 54/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9855 - val_loss: 0.2102 - val_accuracy: 0.9415\n",
      "Epoch 55/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9855 - val_loss: 0.3285 - val_accuracy: 0.9298\n",
      "Epoch 56/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.9913 - val_loss: 0.3036 - val_accuracy: 0.9415\n",
      "Epoch 57/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9942 - val_loss: 0.2056 - val_accuracy: 0.9415\n",
      "Epoch 58/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9913 - val_loss: 0.2114 - val_accuracy: 0.9415\n",
      "Epoch 59/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.2890 - val_accuracy: 0.9357\n",
      "Epoch 60/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9913 - val_loss: 0.1892 - val_accuracy: 0.9357\n",
      "Epoch 61/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 0.9884 - val_loss: 0.2321 - val_accuracy: 0.9415\n",
      "Epoch 62/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9884 - val_loss: 0.2023 - val_accuracy: 0.9415\n",
      "Epoch 63/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9942 - val_loss: 0.2223 - val_accuracy: 0.9415\n",
      "Epoch 64/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9884 - val_loss: 0.3377 - val_accuracy: 0.9357\n",
      "Epoch 65/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9913 - val_loss: 0.2743 - val_accuracy: 0.9357\n",
      "Epoch 66/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9913 - val_loss: 0.1867 - val_accuracy: 0.9298\n",
      "Epoch 67/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9913 - val_loss: 0.2836 - val_accuracy: 0.9357\n",
      "Epoch 68/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9855 - val_loss: 0.2179 - val_accuracy: 0.9415\n",
      "Epoch 69/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.9884 - val_loss: 0.1841 - val_accuracy: 0.9357\n",
      "Epoch 70/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9913 - val_loss: 0.3136 - val_accuracy: 0.9298\n",
      "Epoch 71/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 0.9942 - val_loss: 0.2223 - val_accuracy: 0.9415\n",
      "Epoch 72/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9971 - val_loss: 0.3567 - val_accuracy: 0.9298\n",
      "Epoch 73/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9855 - val_loss: 0.2840 - val_accuracy: 0.9357\n",
      "Epoch 74/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9827 - val_loss: 0.2512 - val_accuracy: 0.9474\n",
      "Epoch 75/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9913 - val_loss: 0.2817 - val_accuracy: 0.9357\n",
      "Epoch 76/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9913 - val_loss: 0.2087 - val_accuracy: 0.9415\n",
      "Epoch 77/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9913 - val_loss: 0.2713 - val_accuracy: 0.9357\n",
      "Epoch 78/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9913 - val_loss: 0.2022 - val_accuracy: 0.9298\n",
      "Epoch 79/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.9913 - val_loss: 0.2013 - val_accuracy: 0.9298\n",
      "Epoch 80/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9913 - val_loss: 0.4048 - val_accuracy: 0.9298\n",
      "Epoch 81/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 0.2660 - val_accuracy: 0.9474\n",
      "Epoch 82/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.9884 - val_loss: 0.2027 - val_accuracy: 0.9298\n",
      "Epoch 83/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9884 - val_loss: 0.2671 - val_accuracy: 0.9474\n",
      "Epoch 84/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 0.9971 - val_loss: 0.4457 - val_accuracy: 0.9123\n",
      "Epoch 85/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9942 - val_loss: 0.2703 - val_accuracy: 0.9357\n",
      "Epoch 86/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0387 - accuracy: 0.9884 - val_loss: 0.1914 - val_accuracy: 0.9298\n",
      "Epoch 87/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.9942 - val_loss: 0.2486 - val_accuracy: 0.9474\n",
      "Epoch 88/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.3009 - val_accuracy: 0.9298\n",
      "Epoch 89/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 0.9913 - val_loss: 0.3456 - val_accuracy: 0.9298\n",
      "Epoch 90/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.9884 - val_loss: 0.1779 - val_accuracy: 0.9298\n",
      "Epoch 91/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.2221 - val_accuracy: 0.9474\n",
      "Epoch 92/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.2897 - val_accuracy: 0.9357\n",
      "Epoch 93/150\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.2108 - val_accuracy: 0.9415\n",
      "Epoch 94/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0231 - accuracy: 0.9942 - val_loss: 0.2607 - val_accuracy: 0.9415\n",
      "Epoch 95/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.2728 - val_accuracy: 0.9357\n",
      "Epoch 96/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9942 - val_loss: 0.3051 - val_accuracy: 0.9357\n",
      "Epoch 97/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 0.2408 - val_accuracy: 0.9415\n",
      "Epoch 98/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9913 - val_loss: 0.2715 - val_accuracy: 0.9415\n",
      "Epoch 99/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.2509 - val_accuracy: 0.9415\n",
      "Epoch 100/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.2601 - val_accuracy: 0.9415\n",
      "Epoch 101/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.2207 - val_accuracy: 0.9298\n",
      "Epoch 102/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.2403 - val_accuracy: 0.9415\n",
      "Epoch 103/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9971 - val_loss: 0.3915 - val_accuracy: 0.9240\n",
      "Epoch 104/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0217 - accuracy: 0.9913 - val_loss: 0.3903 - val_accuracy: 0.9357\n",
      "Epoch 105/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.2217 - val_accuracy: 0.9298\n",
      "Epoch 106/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9942 - val_loss: 0.4379 - val_accuracy: 0.9181\n",
      "Epoch 107/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9913 - val_loss: 0.2917 - val_accuracy: 0.9357\n",
      "Epoch 108/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9942 - val_loss: 0.2778 - val_accuracy: 0.9357\n",
      "Epoch 109/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.9884 - val_loss: 0.2240 - val_accuracy: 0.9298\n",
      "Epoch 110/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9913 - val_loss: 0.3570 - val_accuracy: 0.9298\n",
      "Epoch 111/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0212 - accuracy: 0.9913 - val_loss: 0.3373 - val_accuracy: 0.9298\n",
      "Epoch 112/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9884 - val_loss: 0.3626 - val_accuracy: 0.9298\n",
      "Epoch 113/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.2931 - val_accuracy: 0.9415\n",
      "Epoch 114/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9971 - val_loss: 0.2798 - val_accuracy: 0.9415\n",
      "Epoch 115/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.3670 - val_accuracy: 0.9240\n",
      "Epoch 116/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.3284 - val_accuracy: 0.9298\n",
      "Epoch 117/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9942 - val_loss: 0.2563 - val_accuracy: 0.9357\n",
      "Epoch 118/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9884 - val_loss: 0.3143 - val_accuracy: 0.9357\n",
      "Epoch 119/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.4140 - val_accuracy: 0.9357\n",
      "Epoch 120/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 0.3707 - val_accuracy: 0.9240\n",
      "Epoch 121/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9913 - val_loss: 0.2690 - val_accuracy: 0.9474\n",
      "Epoch 122/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9942 - val_loss: 0.3258 - val_accuracy: 0.9357\n",
      "Epoch 123/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9942 - val_loss: 0.2711 - val_accuracy: 0.9357\n",
      "Epoch 124/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.3837 - val_accuracy: 0.9357\n",
      "Epoch 125/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.2999 - val_accuracy: 0.9415\n",
      "Epoch 126/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.3592 - val_accuracy: 0.9298\n",
      "Epoch 127/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.2534 - val_accuracy: 0.9415\n",
      "Epoch 128/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.9913 - val_loss: 0.2799 - val_accuracy: 0.9415\n",
      "Epoch 129/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.9913 - val_loss: 0.3568 - val_accuracy: 0.9298\n",
      "Epoch 130/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9913 - val_loss: 0.2874 - val_accuracy: 0.9415\n",
      "Epoch 131/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.9884 - val_loss: 0.2373 - val_accuracy: 0.9298\n",
      "Epoch 132/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9913 - val_loss: 0.4042 - val_accuracy: 0.9298\n",
      "Epoch 133/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9942 - val_loss: 0.2863 - val_accuracy: 0.9415\n",
      "Epoch 134/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 0.9855 - val_loss: 0.2883 - val_accuracy: 0.9474\n",
      "Epoch 135/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9913 - val_loss: 0.2682 - val_accuracy: 0.9415\n",
      "Epoch 136/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.3310 - val_accuracy: 0.9357\n",
      "Epoch 137/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.2549 - val_accuracy: 0.9357\n",
      "Epoch 138/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.3163 - val_accuracy: 0.9415\n",
      "Epoch 139/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9971 - val_loss: 0.4735 - val_accuracy: 0.9181\n",
      "Epoch 140/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9884 - val_loss: 0.2736 - val_accuracy: 0.9415\n",
      "Epoch 141/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9942 - val_loss: 0.3579 - val_accuracy: 0.9298\n",
      "Epoch 142/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9971 - val_loss: 0.3871 - val_accuracy: 0.9298\n",
      "Epoch 143/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.3372 - val_accuracy: 0.9415\n",
      "Epoch 144/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9884 - val_loss: 0.3874 - val_accuracy: 0.9298\n",
      "Epoch 145/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0549 - accuracy: 0.9769 - val_loss: 0.3044 - val_accuracy: 0.9415\n",
      "Epoch 146/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9913 - val_loss: 0.3545 - val_accuracy: 0.9357\n",
      "Epoch 147/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.2792 - val_accuracy: 0.9415\n",
      "Epoch 148/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.3893 - val_accuracy: 0.9357\n",
      "Epoch 149/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9942 - val_loss: 0.3082 - val_accuracy: 0.9415\n",
      "Epoch 150/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9942 - val_loss: 0.4055 - val_accuracy: 0.9357\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history=model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1419 - accuracy: 0.9729\n",
      "accuracy: 97.29%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize training history\n",
    "\n",
    "# list all data in history\n",
    "history.history.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABkmElEQVR4nO2dd5zcVdX/32e2t+xmN5u6aYQUkpAESEJvIr1LEQQVRREVCyqC+qg/66MPPhYUQRBs8IBIl16k1xRCem+7STbZbK+zOzP398f93vl+p+3Obna2ZO779drXzHzrnZmd+7nnnHvPEaUUFovFYklffIPdAIvFYrEMLlYILBaLJc2xQmCxWCxpjhUCi8ViSXOsEFgsFkuaY4XAYrFY0hwrBBZLkojIX0Xkp0keu11EPnqg17FYBgIrBBaLxZLmWCGwWCyWNMcKgeWgwnHJ3CQiK0WkVUTuEZExIvKsiDSLyEsiMtJz/AUiskZEGkTkVRE5zLPvCBFZ7pz3TyA36l7nicgK59y3RWReH9v8eRHZLCJ1IvKkiIx3touI/EZE9olIo/Oe5jr7zhGRtU7bdonIt/r0gVksWCGwHJxcApwOzADOB54FvguMQv/PfxVARGYADwBfB8qBZ4B/i0i2iGQDjwP/AEqBfznXxTn3SOBe4AtAGfAn4EkRyelNQ0XkI8B/A5cD44AdwIPO7jOAk5z3UQJ8HKh19t0DfEEpVQTMBf7Tm/taLF6sEFgORn6vlNqrlNoFvAG8p5T6QCnlBx4DjnCO+zjwtFLqRaVUF/ArIA84DjgGyAJ+q5TqUko9DCzx3OPzwJ+UUu8ppYJKqb8Bfue83nAVcK9SarnTvu8Ax4rIFKALKAJmAaKUWqeU2uOc1wXMFpERSql6pdTyXt7XYgljhcByMLLX87w9zutC5/l49AgcAKVUCKgEJjj7dqnIrIw7PM8nA9903EINItIATHTO6w3RbWhBj/onKKX+A/wBuB3YKyJ3icgI59BLgHOAHSLymogc28v7WixhrBBY0pnd6A4d0D55dGe+C9gDTHC2GSZ5nlcCP1NKlXj+8pVSDxxgGwrQrqZdAEqp25RSRwFz0C6im5ztS5RSFwKj0S6sh3p5X4sljBUCSzrzEHCuiJwmIlnAN9HunbeBd4AA8FURyRSRjwGLPefeDVwvIkc7Qd0CETlXRIp62Yb/Az4jIguc+MLP0a6s7SKyyLl+FtAKdABBJ4ZxlYgUOy6tJiB4AJ+DJc2xQmBJW5RSG4Crgd8D+9GB5fOVUp1KqU7gY8A1QD06nvCo59yl6DjBH5z9m51je9uGl4HvA4+grZBpwBXO7hFowalHu49q0XEMgE8C20WkCbjeeR8WS58QW5jGYrFY0htrEVgsFkuaY4XAYrFY0hwrBBaLxZLmWCGwWCyWNCdzsBvQW0aNGqWmTJky2M2wWCyWYcWyZcv2K6XK4+0bdkIwZcoUli5dOtjNsFgslmGFiOxItM+6hiwWiyXNsUJgsVgsaY4VAovFYklzhl2MIB5dXV1UVVXR0dEx2E1JObm5uVRUVJCVlTXYTbFYLAcJB4UQVFVVUVRUxJQpU4hMFnlwoZSitraWqqoqpk6dOtjNsVgsBwkHhWuoo6ODsrKyg1oEAESEsrKytLB8LBbLwHFQCAFw0IuAIV3ep8ViGTgOGiHoiY6uINWNHQSCocFuisVisQwp0kYI/F1B9jV30BXq/7TbDQ0N/PGPf+z1eeeccw4NDQ393h6LxWLpDWkjBMalkor6C4mEIBjsvmjUM888Q0lJSb+3x2KxWHrDQTFrKBmMaz0VdXhuueUWtmzZwoIFC8jKyqKwsJBx48axYsUK1q5dy0UXXURlZSUdHR187Wtf47rrrgPcdBktLS2cffbZnHDCCbz99ttMmDCBJ554gry8vP5vrMVisURx0AnBj/69hrW7m2K2B5WiozNIblYGGb7eBVxnjx/BD8+fk3D/L37xC1avXs2KFSt49dVXOffcc1m9enV4iue9995LaWkp7e3tLFq0iEsuuYSysrKIa2zatIkHHniAu+++m8svv5xHHnmEq6+21QctFkvqOeiEIBEDOddm8eLFEfP8b7vtNh577DEAKisr2bRpU4wQTJ06lQULFgBw1FFHsX379oFqrsViSXMOOiFINHJv7wywaV8Lk8sKKM5L7arcgoKC8PNXX32Vl156iXfeeYf8/HxOOeWUuOsAcnJyws8zMjJob29PaRstFovFYIPF/UBRURHNzc1x9zU2NjJy5Ejy8/NZv3497777br/f32KxWA6Eg84iSEQqg8VlZWUcf/zxzJ07l7y8PMaMGRPed9ZZZ3HnnXcyb948Zs6cyTHHHNP/DbBYLJYDQFIxQk4lCxcuVNGFadatW8dhhx3W7XmdgRDrq5uYMDKPsoKcbo8d6iTzfi0Wi8WLiCxTSi2Mty+lriEROUtENojIZhG5JcExp4jIChFZIyKvpaotvhRaBBaLxTKcSZlrSEQygNuB04EqYImIPKmUWus5pgT4I3CWUmqniIxOXXv0oxUCi8ViiSSVFsFiYLNSaqtSqhN4ELgw6phPAI8qpXYCKKX2paoxqQwWWywWy3AmlUIwAaj0vK5ytnmZAYwUkVdFZJmIfCrehUTkOhFZKiJLa2pq+tQYs47AppyzWCyWSFIpBPHWcEUPxzOBo4BzgTOB74vIjJiTlLpLKbVQKbWwvLy8b40RQUSsRWCxWCxRpHL6aBUw0fO6Atgd55j9SqlWoFVEXgfmAxtT0SAfNkZgsVgs0aTSIlgCTBeRqSKSDVwBPBl1zBPAiSKSKSL5wNHAulQ1KFUWQV/TUAP89re/pa2trZ9bZLFYLMmTMiFQSgWAG4Dn0Z37Q0qpNSJyvYhc7xyzDngOWAm8D/xZKbU6VW0SSY1FYIXAYrEMZ1K6slgp9QzwTNS2O6Ne3wrcmsp2GERSEyz2pqE+/fTTGT16NA899BB+v5+LL76YH/3oR7S2tnL55ZdTVVVFMBjk+9//Pnv37mX37t2ceuqpjBo1ildeeSUFrbNYLJbuOfhSTDx7C1SvirtrUmcAn08gM6N31xx7OJz9i4S7vWmoX3jhBR5++GHef/99lFJccMEFvP7669TU1DB+/HiefvppQOcgKi4u5te//jWvvPIKo0aN6l2bLBaLpZ9Im6RzgJ7HlOJg8QsvvMALL7zAEUccwZFHHsn69evZtGkThx9+OC+99BI333wzb7zxBsXFxaltiMVisSTJwWcRJBq5K8WemmZ84mNqeWHKbq+U4jvf+Q5f+MIXYvYtW7aMZ555hu985zucccYZ/OAHP0hZOywWiyVZ0sci6GhgWmALmaqz3y/tTUN95plncu+999LS0gLArl272LdvH7t37yY/P5+rr76ab33rWyxfvjzmXIvFYhkMDj6LICEm2VD/h4u9aajPPvtsPvGJT3DssccCUFhYyH333cfmzZu56aab8Pl8ZGVlcccddwBw3XXXcfbZZzNu3DgbLLZYLINC2qShpqMJ6rZQ6atg4ti+rU4eKtg01BaLpbcMWhrqIYWYt2qzDVksFouXNBIC7RqSYWYBWSwWS6o5aISgRxeXsQhSECMYSIabK89isQx9DgohyM3Npba2tvtO0lgEqV5IkEKUUtTW1pKbmzvYTbFYLAcRB8WsoYqKCqqqqui2VkEoAE37aKCdpsamgWtcP5Obm0tFRcVgN8NisRxEHBRCkJWVxdSpU7s/qHU/3HoCPw5eww9+8ruBaZjFYrEMAw4K11BSZGp3Skao0/rZLRaLxUPaCUEunXQFrRBYLBaLIX2EICOTkGSQI110Bof3zCGLxWLpT9JHCICgL4ccuugMWCGwWCwWQ9oJQS6dVggsFovFQ1oJQSjDWgQWi8USTdoJQa500hkMDnZTLBaLZciQVkKgMrVF4LcWgcVisYRJLyHIyLWuIYvFYokivYQgM1e7hqwQWCwWS5iUCoGInCUiG0Rks4jcEmf/KSLSKCIrnL/UFvF1XEN2HYHFYrG4pCzXkIhkALcDpwNVwBIReVIptTbq0DeUUuelqh0RZGrXUJ21CCwWiyVMKi2CxcBmpdRWpVQn8CBwYQrv1zNZueTYdQQWi8USQSqFYAJQ6Xld5WyL5lgR+VBEnhWROSlsD5KVa1NMWCwWSxSpTEMtcbZFZ3tbDkxWSrWIyDnA48D0mAuJXAdcBzBp0qQ+N8iXqS0CO33UYrFYXFJpEVQBEz2vK4Dd3gOUUk1KqRbn+TNAloiMir6QUuoupdRCpdTC8vLyPjfIl51Hrp0+arFYLBGkUgiWANNFZKqIZANXAE96DxCRsSK6hqSILHbaU5uqBvlsjMBisVhiSJlrSCkVEJEbgOeBDOBepdQaEbne2X8ncCnwRREJAO3AFSqFVWN82flkS5CuQFeqbmGxWCzDjpSWqnTcPc9EbbvT8/wPwB9S2QYvGdm6OE2ws2OgbmmxWCxDnrRaWZyRlQdAqLN9kFtisVgsQ4e0EgKytEUQCliLwGKxWAzpJQRO3WKsa8hisaSCqqXwz6shNLxS3aeZEOQA1iKwWCwpYvsbsO7f0F4/2C3pFWkmBDpGoLqsEFgslhTQ2aYfh9lgM82EQFsEMsy+JIvFMkzocoRgmA0200wInBhBwM4aslgsKaDLWgRDnywjBP7BbYfFYjk4CbuGhlcfk15C4FgEvuDwUmuLxTJMsBbBMMDECILDS60tFsswISwEw8v9nGZCoGcN+awQWIYqSuk/y/DEuoaGAY5FYIXAMmR56JPw1NcHuxWWvjJMXUMpTTo35HBiBBlWCCxDldqt0N4w2K2w9BU7fXQYYIQg1DnIDbFYEhBoh67h5V9m5UOw/c3BbsXQwHx3w8wiSC8h8PkISBaZoeH1JVnSiK72YdeJ8MrP4L0/DXYrhgadrfrRxgiGNgHJJtNaBJahSle7614YLgT8w6/NqcLOGhoeBHw5ZCorBJYhSqBj2PmXCfjdkXA6Ewq51py1CIY2QV8OWaHh9SVZ0gTTkQy30bUVAo33extm7r30E4KMbLLpIhSyc7UtQ4zwaHJ4dSLDUrxSgTfIP8ysujQUglxy6KIzGBrsplgskXiFIDRM/j+DAVBBaxEAdHk+g2Em5mknBCFfNjl04g8Mkx+aJX0Yjq4Fsyanc4Asgo7GgblPX/B+BjZGMLRRGTnkSBedVggsQw2vO2G4rCUwHV5Xa+pTY1Qtg19Ohf2bUnufvuL9zuysoaFNKDOXXDqta8gy9AgMw47EWC6hAARTPBuvbot2Q+1ekdr79JUI15C1CMKIyFkiskFENovILd0ct0hEgiJyaSrbA6BMjMBaBJbBoGlP4tF+RLBxuAiBp8NLdZzApN6o3Zza+/QV8535MlPj2nvj17Dt9f6/LikUAhHJAG4HzgZmA1eKyOwEx/0SeD5VbYkgM4ccOq0QWAaHu06Bt/8Qf58Vgu4x8YHaAXAN/ftr8PiXeneOef95pf0/aygUgv/8BLa+2r/XdUilRbAY2KyU2qqU6gQeBC6Mc9xXgEeAfSlsSxiVmUuujRFYBgOloGUvNO+Ovz8wHGME3janOGDc0aAfB8Ii2LsWqlf27hzz/vNL+98i6GwGFYLckv69rkMqhWACUOl5XeVsCyMiE4CLgTu7u5CIXCciS0VkaU1NzQE1SrJytUUQDB7QdSyWXhPsAlTikXPErKFhIgTeuMCAuYa2pD4w3dUO/ubenwPaIujvGIF573kl/Xtdh1QKgcTZFv3t/Ra4WSnVba+slLpLKbVQKbWwvLz8gBrly9IxAn+XtQgsA4wZJSYUgiFuEQQDsesbvCPflLuGGpz7tEBzdWrv1dXWeyEIu4ZG9r+Qm/eeIosglfUIqoCJntcVQLRNvBB4UEQARgHniEhAKfV4qholWXnk0om/y1oElgEmLAQtCfYP8RjBHxZCaw2MmQMf+T5MPTFy5Jty11AjSIaeOVS7GUaMS929DsgiGNk/FsHOd2HMXMgpHNYWwRJguohMFZFs4ArgSe8BSqmpSqkpSqkpwMPAl1IpAgC+7FwyRNHZNbymd1kOAnq0CIawEAQDUL8NyqbB7g9gzWN6+0DPGhrjzDdJdcC4q027vXrToXe16nK42fmxMYKWffDUN9zvtb0e/nUNtCRwdXc0wV/OgeV/d1436MfhFiNQSgWAG9CzgdYBDyml1ojI9SJyfaru2xMZWbpuccA/TFZuWg4eTKeSjBAMtRiBmSN/+GVQMDp+XqSBcA2NnqM729otiY9TCt76HTTu6vu9zHfRG6ugqx2y8nRJ3OhZQ6sfgaX3QNUS/XrHO1pMK9+Nf632em35NO9xXjfox7yRybenF6S0VKVS6hngmahtcQPDSqlrUtkWQ0aOFoIuv82NYhlgenQNDeEYgUmfkJWvO7uuOEXaB8I1lDdSWyXdzRxqroYXfwDig+O+0vv7hIJu6gx/ExSMSu68zjbILtCVEAMdWpDECZVWvq8f67fD1JOgYYd+3VYb/1r+psj9xiIYhq6hIUlGthaCYKe1CCwDTDIWQUa283yI/X+aTj67wBGCOCUZEwlcfxAK6s4xr0QLQXdpJsx6g0SdbE94RbijqRfntToWQS6gnFliDsYSqN8R+di6P/61OqKEoL1Bx0eyC5NvTy9IOyHIzNZ1i60QWAacZGIEOUV6ZepQS+ts2pyVr/9M+yKmj6awzaZzzy2BskP1yNrb0XqJHk33Fq8Q9No1lB+ujR527zXtgUZnJr2xBMIWQV38a5n3YISio0GLoMSbjHngpJ0QZOUUABAcqGyJFouhy+NXDwZi9wc6nI4kb+hlHw1bBPnxLYJUi1c4WFoMZdO1/9yMqqMJC0GCTrYnvO+jN0LQ2eZ8fzn6tbEAqxy3UG6xFjBwHxOJVTyLIEWBYkhDIchwLAI11HywloOfiBhAHKugq02PJr0++KFC2CIocCyCqJKMeSMP3DXU0QSVS+Lv806fHDlZP2/cmfg6MAgWQZsrlOB+35Xva5ffjLO0eCnlilhCIYhybxmLIEWknRCI8yWpoeaDtRz89DTDpqsDsnL131D7/4yxCDzBYl+WdmkdqJW97K9w75nxR/Le6ZNmZJyoNsEBu4a8FkFvYgRtka4h8x1WLYVxC2DUdGjdp91EZiCQMFjc6N4/0Gktgn4nKx+AkHUNWQaanubcB9pjffBDhfCsoehgsV+7QrIKkp8++vbv4R8Xx25vrtYun5r1sfvCMYJi/efdFnPsIFkEMa6hDt2J7/4AJi6GkVP19m1v6MecET27hkAf015vLYJ+JVqtLZbe0JtZJNH0NMOmq0P/f5rph0MJM4KNsQg6dMeXXRDf3QXgb4kc5a/8p+4Mo9NVtDvH7FsXew2va8h0iGZbzP2czru9Xt9DKbjvElj/TPxjo/uCA3UNZRrXkB+qV+mpqBWLoMRxaZlU0uMX9BwsBi0EHQ3WIuhXwv47GyOw9JKqZfDLKVC3tW/n9+gaatP/n1n5w2AdgdciyNUdYCIr+9lv61WySumOr3oVhLpcd4/BdIpxLQLn2NwS3QZfZs+uIRXS57XXw+aXYMdbscf+9Tx46YeR2wIHIAQRFkE71DiiNvZwN7ax7TX9OP5InVXUWIprn3Q/V++Ao7XGXUORItJWCHxDbcRlGfrUb3Py3HSzqrU7ehKCQIcjBLlDTwgi1hHk61GuWXhlLIJErqGm3bpDrF4F299wt7fsjTyuJ4vAl6U/HxHtHooWEkOEW6UOmpwVxvGEo3Yz1GyIeq9eIUjSAlQqNkYQ8Luun8LRUFCu9zfvgfxRUDLJbeO+9fDQJ93UHf4m7W4DPcNIhaxrqF9xviQJWiGw9BLjzmnpY+mMiBhBItfQULUIWnVHnJHlWtVd7Vq8MpwYQSLXkHmvax+PrLAVLQRt3QhBR2PkPPrckp4tAtAdcdPu2O2gLZjOltjvM1xXoCx5i8B8X0bIQX82bXV6xlB2oW67cQ+NnKyvb9porEyTVbWjEUqdmEKdM/CwrqF+xFoElr5iRrytfRWCZFxDJkbQgxBULoH37+5bO/qC8X9DeMKFDoYai6Ab15B5r2se10Iwcop+Hd0Bt9dpl0/b/tgVt9E+8tziboLFja6fvq02sUXQ5twjWpBMp144phdC4LGYvHHItlrd4RsBM+6hkighaIhaadzR5H5OxgK1FkE/4nxJGcEhNuKyDH38xiLoY3GkgJ9wmY6EriHjg+9hoPL+n+ClH/WtHX2hs81NbxC2CNo8MYJuXEP+Fm011G2B/Rt14jqI7IBDQe3+GbdAv462Ctob3NlCoDvF7oLFphP1WgTRQmA63bbayAV+plMvHJ28a6jLE0Pxzhpqq9OFagymXdEWQTjlhPO/ZdJp5I10hWCwLQIR+ZqIjBDNPSKyXETOSFmrUokIfsnBF/T3fKzl4CLg732OeS/GxXEgFoEZ1UW7hpTSI9FkF5TVbh7YCQ9dra4lEOEa8kNmtnYNBdp1hx5NZwvMPFsngQOYda5+n14h6GgEFEw+Tr+ODhgb15ChO4vA39Q7IUC51oF5X+LrnWsoHEzP88waMhaBRwhKPBaBSWbXVuuuNDZC0NGkO/78Mh2bgiFhEXxWKdUEnAGUA58BfpGyVqWYLskh08YI0o8XfwB/u6Dv55sRb19jBF0dTi6hrNjRc7BLB6KzHCHoznWpFNRuhVAgcb6d/qYzjmuoq82ZPprr7osnYJ0tumOefLzu3MbO06Nt7+do4gNj5kJOcaxF0CvXUBMUjdVWSIRrKGp07+38vaJkcgbljOija8iTYqK9zh35A5Qe4jxOdWcBtdVFuoaCAS28OSN0UNnkc0qhRZBsGmqT6egc4C9KqQ9FUpT9aAAI+LLJDFmLIO2o365Hmt70wL0hbBH01TXkBIOzC2L96WZ0n5WvO4JAh54D74szVmurdVeedrVBRnHsMf1NV5s7iyXsA2/XnZSZNQT6feUUuecFOvUxOYVw/u90230ZuqaBt/M1M4byy2D0rFiLINo1lFuixSHed+lvgtwR+lptdZEWgfd47/foFSUzjTenqPdCEM4+iv5OTYzAcOhH4WN3w5ST9HebW6wFyesaMu6o3BGRKbCHgEWwTEReQAvB8yJSBAzbor9dvlyylLUIhg21W3SHcqD4m51atH1cFBYOFh9AjCAzR/vaoy0CExMwriFIbBV4p68O1OyiztbEFoGZNQSxM4eMeGYX6vTRExfr14Vj4lsE+SOhfJa2CEyBeqXiu4aCnbGfUcDvCI8RglqnQI3otQvezytCCKItgjx9DbM6OJq3boM7T/C8T8/K64ws7VrqatdrGLyuoYxMmHe5K/D5ZTpu0tUK2UVaFMy02JwR7rm+zJSloIbkheBa4BZgkVKqDchCu4eGJUFfLlmhfuhYLKkn0Kl/cG//7sCvZVwDTXv6dr7p1Npq4/vCeyLsRimIjRF4R5ReH3w86rxCMECpKMwceYgTI8j1WATdCIGXwgQWQV6pFoL2OlccOlu02yzCInCetzdooVj7pG6L+Y5zi3UnWr9dd7LGJeN1J7XWatcLRAmB815zR+jX8ayC3cuherUbZPZ+fyJuDESFIi2CaPLLYNcH+vmEI7S7r8FJppc7wm1fbknKUlBD8kJwLLBBKdUgIlcD/wUkcNANfYIZOWQp6xoaFnQ06h/ZppcO/FrGEmjuoxCYWUMq1Lc8NmGLIM4MGzOy9QpBomDwoFgEbW5nH7YIOjwpJvLd4yLOM6kpCiK3F45xZus4MY6wRVCq/fvgds5mdpDXR26sg45G2LtaL8Za+6T7HecU6Wvt36hfjz5MP3qtwdYaKK7QI+8I11C76xqKPsfQXA0oV8C8SflAfyamVGZPQmDcfBWL9KP5fo1V432/KSJZIbgDaBOR+cC3gR3A31PWqhQTzMglR/lRxvS0DF3Mj3DXUrcj7vO1nJGdWbTTWzpbdZUo6FvAOMIiiHYNOR16pmfWSaJO3lumcaByZsWdNdSmLbbM3MSuIfOdeeMGoC0CcN0zZg1BzgjPPuczjlem0Zt4zoyg67e7I37TiSrHchs92z3e0FqjV/tGWyfhYLERgjgWgYk7mPZ3eVxDoL9Dc4zXNRSNVyQmHKUfzeIyb4wghYFiSF4IAkr3mhcCv1NK/Q4o6uGcIUsoM5ccOukKWiEY8pgfYSgAO97u+3WUOnCLoLMFSibq532ZQhoePRfGcQ2ZYHFucq6hcMc7QK6hiFlDUSuLM7OTcA3FsQjAFdS2Wj2LRkQHkr37vJlHDeFU1A3QWKWfN1a6/y+5IyI72dGzIq9l7llQHhuv8AaLIVYIlHIHE0YIvNNHQX/PYSHoziJwRCJ/VOwCsiFoETSLyHeATwJPi0gGOk4wLAll5JJLJ/5AH/y8loHF+yM0ybr6QqBDiwkkLwSt++HtP7hBy84WN5VwXxaVmVxCcV1DHovApCiIJwRm6uiY2YmP6W9CISdFdpRrqLNFB2AjYgTRrqFEMYJoIfAsvCosj9wXzzXkrUkQIQTGNeQVAoFRM93jQX+OrTVQUJbAIuhGCNrr3eL2Zi2Cv0kHiM3nkJmrE8pB5IKyaEwbR07WogSelBLF7v4hYhF8HPCj1xNUAxOAW1PWqhSjsvLIoxN/YNhOfEof/J4f09YDEALvHPJkhWDdk/DC91xTvbPVzf/SJ4ugmxhBlzdGYFI4xOnkW/Zq98uYuc55A2ARxPN/I67LJmL6aJSlkzBGYEb9Jg7gmV2TW6Lz85jP2BxjzoFI15BZJ9BY5QkWe4TAJHwDt82drVqYE1oEzjoCiBUC7/+PEYKmPdqS8WW4n4mhpxgB6AVmeaWAuIvLhppF4HT+9wPFInIe0KGU6jFGICJnicgGEdksIrfE2X+hiKwUkRUislREToh3nX4nM49csUIwLDA/wplnw95VsTloensdSD5GEM5r3+DOhx8xXndSBxQjiDd91JO0LLMbi8C4DcbMSXxMf+NNnwDafZOVpztvcKaPJlhQZj7DRDEC08l7LQIR3UEbq6tpl47NGCsCImcNGYugIdoicK43Yrw7A8gIhXHpmBiBv8m1ZrzTR8EN5hoihMC5TvNuGDHO3W5cRBk5sSLoJWwRTNFTS/NLnbUZedrlZmIEKUxBDcmnmLgceB+4DLgceE9ELu3hnAzgduBsYDZwpYjMjjrsZWC+UmoB8Fngz71qfV9xYgT+LusaGvKYH/Zh5+tHb/bKvlwnt6QXQuCMbtvrPS6OIt159EWQIvLytLguJ/C4hnI9nWo8IXACxWMPd47ppUVQuwVuP8b1XydDvFF9Vp7rsoleUNbTueb8nGKP+6dOryEwFJS7FkHjLiga5462wUlrke/ECByLINAOdU46hpwiV1hGTNCfa0a26xoy31/+KFdgzP16ChaHpx+LKwRNe6BovKd9jkXgTTgXD69ryLxvcIUru0AvxFtwVeJr9APJuoa+h15D8Gml1KeAxcD3ezhnMbBZKbVVKdUJPIgONodRSrUod+pOATAw0VvrGho+mB/hlBN1aoY9H/bxOo4QlM/UQhBdHSsephNrr4sMeno7qd7Q1e7pNFVkRx92DeV3HyOo26I/h1EzEh/THZte0LUB9qzsRbujLALzPCwEubqTzsyN4xpqASTyXIPxzZuCNV5futdd07QLiifEnp9brEW6eY9eewCwb62+V0aW28mOGO+pYWCKwjtCUDAqNl4RLhCUpy2RGNeQM5AoO9QVlObd+j4GY9V1N2MItIvvsPNh2mlOexwhMNYIwFHXuC7JFJGsEPiUUt7//Nokzp0AVHpeVznbIhCRi0VkPfA02iqIQUSuc1xHS2tq+riq03u9rDyyJEiH364lGBTMqC0Z/M2648su0OZxomIkyVwHdAca6kpuHYAJ9rXXu6KQUxibJycZggE9lTHR4qtwZ5vbfYygfrsePZrRam+FYPcK/dibmVNmlB9tEXhjBBC/1nJnq5uLPxrT2Xe16eCrt9MsLPeMtnfpUX00uSVOypAgTDpGb9u31u1EC8r1cyMSXiEIu4ZGRbqpgl16UoFZGBYvzUTzbi1axRP0dTpb9XW9rqFkhSCnED5+nzsbLTxddETic1JAskLwnIg8LyLXiMg16E47TgHQCOLZQzEjfqXUY0qpWcBFwE/iXUgpdZdSaqFSamF5eXmSTU6ML1v777r8Q6xAeDqw9TW4bYGuyJQM/mb9YxTpPvVwTxjfsBlJJ9MRRriGjIujUAcFe5tmwiwYMzECiBw9h/f3ECNo2KkrW2Vk6Xn3vXUN7XZWsfZmLYVZGxBhEXhiBEYI4gXB/c26s4tHYbnufM1iMq9FYD7jUEi7sRJZBCY53URHCNpqXZHMyoWvfgBHflq/zhnhWobxXEMte2Otn3iJ55qr9ei/wBEr4yoqimcRdBMojkc8i2AASDZYfBNwFzAPmA/cpZS6uYfTqoCJntcVQELHpFLqdWCaiIxKdEx/YYQg4Lc1CQacyvf0Y7IjUiME4CYa6wvmx1zuTCNMpiPs9AiBOT+70B2tJuNeMpjqZAktgnYdWPT5PPP04ywWM0IAva9k5m9xV9r2ySKIdg0ZIXA6veyC2E6zszVxsLRovB7tm8ybERbBaD0yr9uiRTKuRVDsdtzj5rkL8byj6YJROghrjvfGCLIL9XvKHwWIY514gvYQ3yJo2q1XPxeUa+Fpdrq1CIvAEyPoDWYNxRC1CFBKPaKU+oZS6kal1GNJnLIEmC4iU0UkG7gCeNJ7gIgcarKYisiRQDba7ZRSfM4/ZqDjAFeqWnpPteObTnYk6292R0eJLIIX/guW/6Pn6wCMmq4fe2MRtNVFBj0LnE6qN6IUHvHnJBYCExvIyNLusHhulrZajxDEqVuw5jG4dXp8EaleSdgo75VFELVqNvreptMbM0cH872LtjpbEidLm3eZ/lxe+6V+HWEROCNjY8HEEwLvlMriCte9kmg0He0aMp10RqYWjHgWQe4I7Y579Zew3Jko2Vytg9f5ZdrCMNM9vRaBEZLu1hDEw7iGhpJFICLNItIU569ZRLpN4aiUCgA3AM8D64CHlFJrROR6EbneOewSYLWIrEDPMPq4J3icMjJz9JcUPFCLYMk9sPO9fmhRGmGClImqWUXjb+rZIvjwQdjwbA/XadQj12Kns/AKQTAQX2AiYgSeYHHYp9yLOEGPrqF2d0QL8WsSNDghN1PcJCsv1iLYvUIHsqPLL5p9AOPm99IiMCIYZREYMhwhOO4r+vta+pfIcxMJwfgjYPoZ7kywaIsAXCFI5BoCPZMrt1iLASQeTUcHiws8buaisbqDD6f6cEQ5t0TnMnr15/D0t/T/Ses+1zUE7v90v1gEZtbQAKQW99CtECilipRSI+L8FSmlepQspdQzSqkZSqlpSqmfOdvuVErd6Tz/pVJqjlJqgVLqWKXUm/3ztronw/mHDnYeoBC8/GP4YNimXBp42htcN0BfhCCeRRByEsAlKlISvo5jWWRk6R+btyN8/y74w8JYV0941pBHCHKK3KRoTc789WAA3vxN923o0SLocEeREH+0b3LqRLiGoo4Jz8uPM711zwo9kh23oI8WgafzNx0luJ3e+CPgkFPg3T+6Fkl3MQKAk77tPvd2mgVRQjCiIvZc01kakSjuySIYEbmOwCsEJZN1TYCwa8h5r6f9AC6+Cy7/hw5of3CfTjpoXEOgLa3sosi1EgdjjOBgIzNX/xCDyXZG8VDKyW9v6xokzd417vOkhSA6RtAY2WG31+sfZk9umg6PoJjRn6Fui+4YTCbJ8L3jBYsL3ARm1av04/Y34KX/BxueS3x/b3bRRLOGvEKQmRv7v2VENMI1FDWYMULQGsfDuvsDLQJFY/X79dbp7Y5E6wi8bTUc/3XdhpUPuud2t6Bq4iItHkjkoiljEexZqd1k3k7bYNIujEhWCIq15RXwQ/NenV7CUDJZf77mvZr3N2Y2zP+4Lq9ZUA5L7tbbizwWQfXqSGsAkp81FM0QnzV0UJGVo9U+dCAWQVe7nrY2UEm/DgZMfAB6GSPwWAR4kseBJ3tlQ8/XMT+uovGRFoE5N9pdEg4W1zmi4MyHzy/VHYdxtexa5rSlG1dROFick3jWkLdDjTfab9ipF0WZ0XJWfqz7qDmBReBvhv2b9Ki9aCygkl8L0dWm59NnZEe2z5Dp2X7IKVooV/7LfY89FVQ5/zZdtSvDk74st8SZFdWqO9l4ldrCFkFF5GNC11CJfty7Wr/3sfPdfSMn6/fZWBn7/kCvk5h1niceMNbttLtataXlpa9CMHIKHHsDzDird+cdIOkpBLn6S1YHsjzfBB+tECRP9SrdiWVkxy48SkS0RQCRo3/T4SXlGjIWwZhIi8Bcr9njVw85Ii8+LRT+5sj58OPma1cLuELgjRnsXRtZ2SoiRpDINeT1wefGdvKNlXrUazrFeO6jFpMVM0oIdn8AKBi/wO20jPBte6P7QjumFoF3LUAii0BEL5LyugB7EoKRk3Xg2IvP546447mFIFYIegoWm+0mnjTleHefibuY6aje92eY7VkP640RQGww27jDjGgniy8DzvxZyheQxdx2QO82RMjK0T9EdSAWQVgI7BTUpNmzUqdGiFezNx4BpxShd9YQRI7+w2mAm7t3dfib3OuYWrZmXoK5XotHHIxQFY0HlJ4i6HVxjF+gR4ft9VC1NLItrft1VTXjHoFIiyArD5A4rqEoiyD6M/JOHYVY11DQs1Au2iJ4+w86pcOkY9wYR3M1VC6Bv50HHz5AQry1CLztM3iFAHSH3LRbf3+dLd3HCLojLATj4+83/w+mEy47VFsRxT0Ix/pntBuq/DB3n0kB3Z0QTDlBn+fL1FNOswvcAH+0a2jOx+DKf8YPcg9B0lIIzDqChBWgksG4J6xFkByBTr0KdNw8PQ0xmRiBN0AL8S0C78i3O6sgYhpqqV5dbK4ftgg8riETHzCdSkNlZIc2boF+3PCsJ0um89iwU7sNTUFyiJyNIhKbeK6rPbJDzS1x5+kbooUgM8oi8Fok3s9l+1uw6Xk48UbdGXotArOuY23EzO5IvLUIDN6O0usyAm21qKCbTrm7GEF3mDhBos509GxdzGXysfp10Vj42ofahRMPIwT71sCk4yLdTeZzrXEWOsZLiZGRBYdfplcq+3xOcjzHPRTtGsophJkD6945ENJSCHos/JEM1iLoHTXrdedrLILoSlbx8JYdhAQWgVcIPNuj8QaLjd/WrGg1Ha7XNWREwnQQjZVRFsER+nHJPfqxcIwnE6UjKN4pnF6LwLwXb3C6bb/bqYAOZHpH9Z1t+vrdWQRei8Z8LkrBSz/UHdXiLzjXLtcur+Zq16219ZX4lbjAsVbiJI0zxLMIwB1d97Xoulnxm8g1VDAKPv8ftx4xaOGOF0+AyCmZXrcQaKErGO2mtI5nEQCc+XO49sXINkBiq2WYkNZCINE+2N4QtgjSXAhWPwIPJpEZ8d07dMCxYpH+0SXjGopOYRzOQd/gHtOWhBCY6mS5HosAdEesVPeuoXBFsprIDi2/FIon6RKaGdk6SBojBJ4RujeFBDgzl5zjgl36XO+oMn+UdvMY95UJYhpfNsSuLDb3yy1xP5etr0DVEjjlO+6o3uekdG7eo4VgRIVOfbzpRS2O/7zanREFjp8/gUUgGe7KXUOxI1YHKgTGNdRf7hVvEHnycbH7R3o/2wRCkJEV+VmYNkZbBMOM9BSCTCMENlh8wKx4ANY/FRkYjWb90/Dh/8GJ39Qj2nj5+OPhLTsIrmsoXowgeruXzhZAxbcIOlvcurbeAHLYNeTJkhLdoY2bpx/HztN+6nBunCQsAu8UVnOc8d2DHml6Vy+HF5NFWwRtrliY642Z61oEJlvrnIsj2140Vk/nbdgBiz+n4ybrn4KnboR1/9bfmcEUavHiLckYjXGn1ThC0NcYgXEN9ddo2wwkckbo7ywaI7K+rMgZTN3RUxxjmJCeQpCRSYAMfMEDsQicTiqZke3BSigEVe/r54myebbWwr+/pn94J92kt2XlJ+kairIIsgt0oC4iRlDrzj9PFCMIXyfaIqj3iIckcA15hSDKPTJ+gX6ccJSbG6ejwdPBx7MIHDdK0ThXMMzx0RaBeX/gWUPgaU9Wnl5DEXRE2AjK6MPc76N+h36/0VMqC8e6i7UqFuvCP2seg7WP623GVw7urCEvRhjiCYHJ32MSC/Y1RjDlRP1nykweKNmF2iU26ZjI2gYGEzCOFx9IRHGFdpvFW+cwjEhPIQA6ycZnRml9wbiGgv7up94dzOzfGJvfPZr1T+mR8vm/c+ebx8tSGQ+zCtR04CJOELXBPaZtv54tAoldQ9GC4rUIzDmlU7VryIyu41oE0ULgxAkqFrodQcs+NwlZ6z538VuMRTBOp73obHWFwFuBy/iezefasFOPVAs9VkN0VbCWvXpkXzRWC1lXh5u2OhpjfYhPC9qs87WoTD5Bp32o2eAeG3fWkLEIouIDhpKJbonP7KL4x/TEuHlwzVOxbqm+IgILr4VFn4u/33xOidxC8Tj2y/C5F+MLyzAibYXAL7lkBPvBNQTpGyeofNd9nqhil/GDm4pa0IsYQVSwGHSQNcIiqIEyJ5FcItdQuI6t4xoIu5jq3HPKZ+mRtQkcmzxDuSV62mV0OwAOOVUvhpp9oSsErTVuxx4KuAHhQLvuyE2HEZ65U+1+Rl6LwAiBcX017IwNhEZPemjeq8XEKyINO9yRrhdzr9GztcAdehp85L/gkj/rbfs3udNx484a6sYiAHfmEPTdIkgF5/4KZpwZf19JH4Qgt9gtGzqMSVsh6PJlkxE6EIvACgGV7xMuO5HINdS8R7sJvD7X3sYIvB2w1yIIBfWovrgisgxhzHWiBCUjU/+A2+rcjt8ULzGduLEIcgrd2UrRHZovA476tO4MjT+7dZ+eQ29cO8ZdY8pUGsJz+ffoe0pG5KyhsGvIFEffFTs/PrqkZUu1FgLvvRsqIwPM0fefcKTzmWRp192IcfqzCHVBvVNAqLtZQxkJhMAby+hrjGCgCVsE/WSBDCPSVwgkh8xgAiFo2h1ZTzYeEUKQpnGCyvdg4mL9PKFFsDd2RoWJESTzGYsv8ofptQja6gClR+Pd1SqIa1mM1KN1c44RAjNzyFti0cQguhvZmhWkDZX6miZ+EBaCjsgFYya42Fyt/wrHRLoXol1DjfGEwFgExjW0LzL1QfUq3aF3ZxFMOCp2n6nZsG+d/o7izhpKwiIwDCWLoDtGVGhB7o1FcJCQvkLgyyUrFCdY3LoffjvPDZolYiAtguZqePYWPc1wqNC6XxdSn3Gm7qwTxQia90TOhgHdMYQCbpAzEd7qZAavRRCuO1vm1K9tSHwdiEw9kFfqWATOOaOjLAJvicWwEHQzss0bqTsRk09pnJPHxgSMu7UI4nxGmTnat95aq100zbu7twiU0qJTONp1U5k1AvFiBBMX6dWvM8+J3WeEoGaDEzRWsbNikokRGPo6fXSgyXBWJVshSB+CGTlkqjgWQfMePYrqqbh3hBAcQBbTZNj8Mrx3R+RMjsGm0pktNOk43QkmtAiq4wsB9Owe8q4GNngtgnDd2XJne0+zhjwWQX6paxFIBpROc9sbvrfTgSUjBD6fHomb6Zpm5bHXIvCOnnNG6I68aY9b6CQas6ispVoHcqPz2XgtgvZ6LayFY93Ux1WOEMRzDeWNhMv+4rq0vGQXaNdOzXpY8zggMPPcyGOMAPRkEWTkJD8VcyhwxNU602iakdnzIQcnAV8O2aE4tXVMZ2L8o4nwNzm+7pbUWwSmIzMrYYcCVe/r4Of4Bc7ipzhCEApqn3l3QtBddkZvLQKDNxW1t+6sdxHVUzfqDujsX+jXHfFcQ6U6INreoEUkp1B3zqbj9mbNNG3sydddMFpntgRdCS2rILFFIKI7f2MRmOLrXvJH6ffY6Kx2Tega6nDbXThaW0e+LD2PX3yRbppkKZ+lLYK9q/Xiq6Ixkft7cg2FE8ANE2vAcPK3ez7mICSNLYI8slQc14QRgrqehKDZHU0NlBBE58sfTBoqXTO6YFT8/PetNW4RDy/R0x4T4c0Yasgr0dfsbHaFwFgExs2z4VlY/bBnKqiTOdTrg88v1aPojgZ3FpFZbQs6WBxjEfTg6y4sJ1wKsmic/v8wHXRXe2ynWTROz+ppr4v9jEB/rm373QI4MRaB53MMr0UYq0Umv8y1IrxpopOlfKbOyVOzPjLrpiEzB5DErqHcEu3aGi7xgTQnbYUglJFLTjzXUNIWQbM77zvVwWIT7BxKFkHrPlcI88vizxqKNy0S4ufjj0c8IfCuLm7bD4ju1E0ZQn+zvm9rjVvRy98Yx8VUqj/X1hp3VlDRWHdRmdciSMY1BJF1AnKL9f9HollD5n7Vq93n0eQ7Ahu2CKKFwLleV7treZh1BiZgHC9QnAzls7SQIHDYBbH7xQmkRyec8+4vmdj3NQSWASV9hSAzhxy6EYKOxu473nS3CFo8pf4KEriGvKNUL2YGSk9rCRJZBKBH8q01TlrgDNdltH+Te2zVEv3Y3hB7HePuqdvuikvRWHfWkL/Fk+zOObZHITCZKJ1ReeFoj2uoI1YIRozTCxKh+xhBY5Vbl9eL1yIw7faKM8SPDySDSdE86ZjYFMvh++cltghAp202QXPLkCZthUBl5pFDJ8FQ1BRGb8AxkVUQ8LuBORgAi8DECOq7P24gibAIRmnRjF5hHV4xeyDB4m4sglZPAfK8Er2AyRSLAV0nINgF2990p3MazCi/sdIVl0KnYI1SkRbBrHPgjJ+5U0wTYT6PovGR14MEFoGng01kEQQ7ta8/XuI174Ky+u1aKMzndcAWwUz9WR9xdeJjjr4e5lyUeP85t8LFd/Tt/pYBJW2DxSozlzw68QeC5Gd7PoYOTwC5blv8edamYzYBtFTnGwpbBENECIIB3fF7LQKUbp93UVRzNSCxM1PM4qSeZlslmjUEjkXgSd1sRstVy/Q9JxypLYLtb+hjo90b4SC1ckWhZJIeuTdXO0JQ4F77uBu6byu4riHTqReO0fcO+GNnDXmPgwQWgfPe9nyos7ZGk+kRgtotOtWGmWprvpt4U0eTIacQbtqsczsl4uSb+nZty5AjbS0CMvPIk078nVGj2I5Gt2NIZBEYq6HgIHQNPXEDvPSj7o9pqyW8kAtcN0T0FNLmPfqY6OmDyVgEwYAWimghiLAIajxC4GzftVR36FNO0HP6Vz2shefQ0yKvk+eZrWTOHTNXP1avjAwWJ0uhyUTpdOpGAFv2xXcNGcvBlxXZHoNZIdzRGBsoBj3vPSNbW6RGCKLP7atrCPT35l3DYTloSV8hcMxqvz+qE+9o0D/QwrHafxwP0zHnl+ofcapdQ50DOH100wuw463ujzEVuUxHF70K1tCyN3baIXiEoJvPLd5qYHAtgrd+C7Wb3BxGZnvNej11c8JC7Vb58EGYfnrsIiHvtFVzrrnW7g90bqDeBjoL4riGwCMECSyCwjHxi6l4ratE5Rez8vQAoakqUgjKpmnhGTW9d+/BkpakVAhE5CwR2SAim0Xkljj7rxKRlc7f2yIyYJElcTqGro6omSsdjdoVUDo1sUXgXaAUXRwkFQyURdDZpjvvRIvDDCYAWuCJEUB8iyCeyyMsBN3MGjKVoqIDldmFegFY3VZY9Hk44Rt6uxnVg+4QjStFBWF2nFkv8SyC3BG62tWOt/Xr3loEZYfqRHSHnKxfhy2Cvdo9FC1GRgjixQcgUgjiWQSg///2rtHPvZW6Zl8EN67pfp2GxeKQMiEQkQzgduBsYDZwpYjMjjpsG3CyUmoe8BPgrlS1J6Z92UYIokalRghGTk28liBCCPIGMFicYiEwOe8TpYsweFf0QqRFsO11uP9yvcgp3qpi0O4Myej+czOFWEy1K4MIzL9SB2/PudVdG+CdUVN2qBaQERV6VDz9jNjrZxe4Ux+NRQC6boJZNd3b1AjZ+fCpx91slOa9r7hfv9doiyArT7shEwlBvtciSCQEebB3rX7utQjMSmeLJQlSGSxeDGxWSm0FEJEHgQuBteYApdTbnuPfBRLYv/2PL2wRRLuGGnUa3tKpuqpWV3vsSM6buya6bmwqMPfraNArahPVZO0Nm1/SaRVKp7rb6rc792nUs20SpQYwQlAYHSOohW336ELpqx5ykqDFsQjiFW+PJlyacVLsvotuj93m7cyNO2TRZ/U9ot1Lpg15pXrapdeaGOfJM3Wgq2ILx+iiLxue1ZZJ9Owp0Bk/R82If352vmNxtiWu25uVr91YoN1BFksfSKUQTAAqPa+rgKO7Of5a4Nl4O0TkOuA6gEmT4nQMfcCXo+dgd0V3Rl6LAHSFp9FR0wa9/uvsgtRaBGaqqknj0NHQP+b+vz6j3SeffNTdZoQAdEA40Ui1ZZ9O4WACuRlZ+jNr3gNb/qO3vfpLQEUWW/GSnd+9EDTs1LNikh3VZhfpdAoq5NYnOPGb3Z+T7wiBmRwAkfPeD3QxlC9DFy0JdjnxkjjlDI/9cg9tHAWNOxOXQjSDlMIx8QXPYkmCVMYI4k03iJt3WERORQvBzfH2K6XuUkotVEotLC/vn5JwWY4Q+Ns8fupQyClyXuyOlE2VJS8D6Roy9zLTAPtjCmlnq36fW1/RKbcNXiHoLk7QWqP9394ZJfmj9MjX3wTTz3TTIiQq6t1TlTJTiCXZWSs+n/7esgqSrx9r4gQRriGPEPRXnpyMrNiiMslSUKYtrkRVuowQeN1CFksvSaUQVAHebFcVwO7og0RkHvBn4EKlVILqJv1PXqEezfpbPQvIOlv0iDK32F2IY9IUePE36/nVmbmpdw0Z66OkH4XABHtVSM+qMURYBN0IQcu+2BqtBaP06DojBy76ozvKTmRVGJdHIhorI1MZJ0NusXaPJCse+U4bva6hwnJXvIZCnpySya6FEw+zuti6hSwHQCqFYAkwXUSmikg2cAXwpPcAEZkEPAp8Uim1MYVtiSFvtP5xZdR7RvxmfUBusR4t+jLdXDFevHnye+rQDpRoi6A/AsZGCDLzdCDTJGer3+6OLLu1COIIgYkTTD1Ri8JR1wCSeNpjTzGChsr48YHumHpy/Pz6iTDfcXSHP3ae28bB5rzfwOV/T7zfWgSWfiBlMQKlVEBEbgCeBzKAe5VSa0Tkemf/ncAPgDLgj6JHcQGl1MJUtclLUflEmlQeeQ2e3DRhIRjhzLood+fMe/GmPki5ReAIQdgi6A8hcMTtqE/De3fqFbgVi7QQzL5IF5xJVHoStEhE55AxQjDdqQd78i36ebx896BdHYlErbNNWyS9TZ98wW29O37OxU5BmSgLYtx8HfCOXsw2GPQUDzIWQam1CCx9J6UpJpRSzwDPRG270/P8c8DnUtmGRGRnZbCWCkpatrgbvRYBaCFoqYk92d/sFjRP9ToCUzvXjI77wyIw4rb4Olj+d20VmPQKE46Elf9MbBGEQs6K3qgO3nT4M5ypmlm5MPnYxG3ILnCniO7fpFfzNu2BIz/l5ufprUXQW6adqv+iWfhZbdUU9k88KqWY1crWIrAcAGmbawigMmMS09qWuxuihaBwdKRFUPm+nproLZiSlZdcIfa+YiyC4go9K6ZfLIJ9+lojp+hc86sfdXPOl07To+REMYKOBl1mMnqkf+SndWeUbJKzLGe2VfVquPN4zw7lZr7sS0GV/mDEODj6C4Nz796SXeB+lxZLH0nfFBPAnuzJFAXr3aIqMRbBaNciCHbBX8+FB6/SneGAuYaa3DbllvRTsHivduX4MmDBJ/Q93v6D3jdyilNoJoEQhFcVR42WR07W10qW7AIdnN/6in79med0ds9NL+rpkpB6i+BgYNG1cNnf3NoEFksfSGshqMt3poju36Afw0JQoh8LnRiBUnqaZbBT5+GpXuURggK9oCcUSk0jvVNV80v7L1hs5vdPPkF3uFteBpxiIgXliWME0auK+0p2vo4F7Hhbp0aYfKzOCbTjbdi3XgdxE804sriMnBI/hYbF0gvSWggaCp0AmykKb4TABAkLRuvOv6NRFwcB1wT3WgSg/eupwN+sTf+sfD3LJZ5ryN8CD3/WbSNoN1btFndGkJcWTy0Bnw/mOyP5ERN0GoT8ssQWQXTCub6SXaiLsmx/CyY7rqFDT4dQF6z6l26Lt7SkxWJJGWktBKqoglZydZFu0B1+dqFO7wuRaYRNJ/uxu7Uf3eSTCVeJSpF7yDtVNZFFsPMdWP2IdquADrrecwb8/kj47eGw453I41v2RQZ7F1ypH43IJao4Bq6rLDpY3FvM5+ZvdIVg0rH682+vs24hi2UASWshKC7IZouaEGkReJOXGfdH6z53peyYufCVZbD48/p1uEpUitYSeIuz5I2MHyPY56RvMgvCajcBSmfnbN0Pax5zj1VKxwi8I/qRU2DxF2Duxfp1oopjoD8LyYhMy9AXvHP3Jx+nHzOz4ZBT9PPBChRbLGlIegtBXhYbQxNQ+4xF0BApBNEWQV6p9m17550nEoKWffDX8+CJHnLJ9IR3hlJeAotg3zr9aITAPB53g86xX73KPbajUbtkonMAnfM/sMiZyWsqjsW7V3O13n+gie+MEBRPjKyidehH9aO1CCyWASPthWBTaALSskdXvIqxCBwhaK2Bxl3xV8l6C4gbajbAn0/TZRLX/vvAAsnexWv5I3XVroA/8hiTj96kka7bpoOtIyp0Ns3qVW4bwplDEySDA3dxWLR7SCld/zde+c7eYoTAWAOGGWfqz3TcvAO/h8ViSYq0FoKS/Cw2KSfPe816N+GcIb9UB2qNRRBXCDx1Yw1P3KBfL/q89oHHS1yXLF4hMEnSvO6hUNCNcYQtgm16RJ2RqdMldDa7RXbMquLuFkuZjJ/RAeO6rVpspn2kz28nTCIhGDEebtrSu1QRFovlgEhvIcjL5oPQoYQkE9b9O9Yi8GW4aSaaEgiB6dCMRRDw61KHC65y8u0Au5fHnpcsnS0ei8AZqXuTw9Vt066e8sO0QLQ36G0mjbYZWVev1I9hIejOIkhQenLzy/oxuv5vX5hwlF6EFl1UHmLdbxaLJaWktRAU52VRzwhqxp+qs3C21UUKAWj3UN22xAXEoy2CfWv1FMjxC/QCqcw82HUAQuBvdpOfTT1Ji8GLP3BdPfsct9DMs/Vjww49+jdptEfP1m6iPUYIknANJbIItrysBcZbErGv5BTp3EC2lKLFMuiktRCU5OsKXJvGX6hHv9GuIdAulN0r9PNuYwSOEOz+QD+OP0K7ZsbNPzCLwDtrKL8UzvgpVL4Hy/+mt+1bB4j2rZv7dzS6FkFmjhYkEzBu2auFwZt6OZpwjMCzqCzQCdve6B9rwGKxDCnSWghG5Gkh2FB4tDtCjmcRdHry/URjLAKTb2j3Ct3JmmyhE47Uo/FgoPcNDAUjXUOg6/VOORFe/KFeL7BvrR79j3by82xxUjZ4S1COPdzjGnLWEHQ368dUHGvdrxelVS6BnW/rQPU0KwQWy8FGWgtBUU4mPoH6DqU7WIhvERiSCRbv/kBbA8bHPf5InYKiZl3vG9jpZB71CoEInPdb7X565HM6advo2U4NhZGw7TV93EivEMzTlkDz3tg1BInIHwVrn4A/LIJ7Pgr3X6Ytiakn9v59WCyWIU1aC4HPJ4zIy6KxvUunP84phlEzIw8yU0jFF7/4uHf6aFeHdtWMP8LdP+FI/RgvTlC31V0DEA9vniEvow7VBUt2vAl1W7QQgF4YZmYUebNRegPGrfu6jw8YRozXU02P/CRcfJdO/3D09bYursVyEJLWaagBSvKyaGjvgrK5cMuO2NkqZvRcNN5NPeElI1uLRFe7DtyaQLGh9BA9Wt+9XBeC6erQ/v3lf4e9q/X5173qpqzwkkgIAOZfoef0f/AP1y00coq2SArHRNa4HXu4Hs0/cYOOH4w9vOcP5oLf6/c0xhGZ+R/v+RyLxTIsSWuLAPTMocb2Lv0i3pRFk2aiOM6MIXNOVoHuNE1Q2WsRiOipksv+BneeCLcdAc9+W7uUTv+Jjic88nktENGEhSBBpaxzboVz/9edc2+sAK9bCLQQfeKfzkIwFVmgPRGlU10RsFgsBzVpbxEU52fT2NaZ+ABjESSqvQu6U2/aBc179KKv6Dw55/0GVj4E217XM38uvhMOOVnvK58J/3c5PP5FPVIvGKXdVODWIkjkjsnKc9NCgCsEpVNjjz30o/ovFDrw9BAWi+WgIu2FoCQvi5213VQYK0hCCPLLYO3j+vmhp8daFiOnwMnf1n/RzDgTjv4ivHcHrHnUadRkLRT+OMHi7khkEXixImCxWKJIeyEoNjGCRBSUw+GXdZ/y4BMP6nw//haYdHTvG3H2L+Ckm3Qnfcfx8J+f6MVjJodQbpJF1MsP0zVs+yMXkMViSRvSXghK8nWMIBRS+HxxYgQ+H1zy5+4vMnLKgdeMLXAWcZ18M/z7q/DszbDkbph5bvwVzfEoGgPf3hqZ4tlisVh6IO39BMV5WSgFzf4+LPhKBQuu0oVv3v+Tjhlccnfv8u5YEbBYLL0kpUIgImeJyAYR2Swit8TZP0tE3hERv4h8K5VtSUSxs7q4sa0b99BAkpEJ5/5Krx6+8p+2Y7dYLCknZa4hEckAbgdOB6qAJSLypFJqreewOuCrwEWpakdPhIWguzjBQDPtI/2T6tlisViSIJUWwWJgs1Jqq1KqE3gQuNB7gFJqn1JqCTBovXBJfjYAdd1NIbVYLJaDmFQKwQSg0vO6ytnWa0TkOhFZKiJLa2pq+qVxhumjC8nwCUu2xSnLaLFYLGlAKoUgXoRT9eVCSqm7lFILlVILy8u7qazVB0YWZHP01FKeW1Pdr9e1WCyW4UIqhaAK8C6xrQB2p/B+febMOWPZvK+FzfuaB7spFovFMuCkUgiWANNFZKqIZANXAE+m8H595ow5Ohvn82v2DnJLLBaLZeBJmRAopQLADcDzwDrgIaXUGhG5XkSuBxCRsSJSBXwD+C8RqRKRJJfR9h/jivNYMLGE51Zb95DFYkk/UrqyWCn1DPBM1LY7Pc+r0S6jQeesuWP5xbPrqapvo2Jkfs8nWCwWy0FC2q8sNpw9VxedeWLFkAxjWCwWS8qwQuAwuayAYw4p5YH3dxIK9Wlyk8VisQxLrBB4uOroyVTVt/P6phrqWjv50v3LWLbDri+wWCwHN2mffdTLmXPGUlaQzd/f2UGLfwvvb6tj494Wnv3aiWRlJKeZXcEQ9727g4qR+Zw+O4nawBaLxTLIWIvAQ3amj8sWTuQ/6/fx/rY6Ll9YweZ9LTzw/s6I45btqKe2xR9z/obqZi7+41v86N9r+d5jqwhaF5PFYhkGWCGI4hOLJ1GUk8nXPzqdX14yj2MOKeU3L25kR20rDW2dfOOhFVxyx9t8/K53afDkJ2ps6+KqP7/LnoYOrjp6Evua/by7tXYQ34nFYrEkhyg1vEatCxcuVEuXLk3pPfyBIDmZGQCs3tXI+X94E/MxZfiEyxdW8MiyXSyYWMLfr11MblYG33tsFQ+8v5MnbziBQ0cXsvCnL3H23LHcelkSheItFoslxYjIMqXUwnj7bIwgDkYEAOZOKObfN5zAh1UN1DT7+cis0cyrKOG4aaP4ygMf8LE/vs2lR1Xwf+/v5DPHTWXuhGJAxxueW13NTy6aS25WRqJbWSyWNOfDygYOn1Acv0LiAGFdQ0kwd0IxVx09ma9/dAbzKkoAOH/+eO646kiaOrr48VNrGVOUyzfOmBE+56IjxtPsD/DK+n0x1+sKhoZW/QOLxTIorN3dxIW3v8ULawc3q4EVggPg7MPH8Z9vnsL/XDqPuz51FIU5roF13LRRlBfl8Mvn1vPnN7ayu6EdgNoWPxf/8S1OufUVKuvaur3+v5ZWctWf3+3X6mkvrd3LLqctluFPR1eQqvru/48sQ5fVuxsBWLWrcVDbYYXgAMnO9HH5wolhS8GQ4RN+fvHh5GVn8tOn13HS/7zCNx/6kI/f9S6b9rYQCCquv28ZHV3BmGsqpfj1Cxu46eGVvLW5lvve29Evbd3V0M7n/7GUnz61tueDLT3S2N7Ft/71ITXNsTPIBorfvLSRs377Bu2dsf9HlqHPxmqd8XhDdcugtsPGCFLI6bPHcPrsMWzf38pf397Og0t2kunz8bfPLqbVH+Davy3lxn+u4L/Om8344lzW7G7iqZV7eHrVbirr2rl8YQV7Gjv4y1vbufaEqeFYg1KKxvaucHW1ZHlkWRVKwUvr9lLX2klpQe/Ot0Ty/JpqHl5WxayxRXzuxEMGpQ2vb9xPiz/Au9tqOXXm6EFpg6XvbNjrCMHepkFthxWCAWDKqAL+3wVz+Opp0/EHgowrzgPg5rNmcevz63l+TTVjR+Syu7GDTJ9w/KGj+ObpM7lwwXje2VrLJ+5+j0eX7+K4aWX8/Z0dvLiumsq6duZPLOHKRRM5f/54CjxuqZ21bdz2n00cUl7ApUdVMLool1BI8fCyKiaX5bOjto3HP9jFZ0+YesDvbd2eJpbvrOcTiychMnjBrsHg9Y26Wt6bm/enTAiaOroIBhUj44h2Q1sn66t1B/LahhorBMOQjY4QVNa10+oPRPyOBxIrBANI9Aj8i6dM4/z547jv3Z1sqWnhq6dN58w5YyN+9MceUsa8imL++9l1tHUGyfAJJxw6iouPqODZVXu45dFV/OSptVywYDxHTBqJUoqfPr2OzkAIfyDEr1/YyI2nz+CoySPZWdfGbz4+n7+8tZ2HllbymeOn9Nh5N3d0EVJQnJcVs6+m2c+n732ffc1+2juDKekMd9a2ceNDK/jyqdP4yKyhs1I7GFK8uXk/AO9urY2YctxfKKX4zF+WUN/ayQs3nkRm1Or2d7fWoRSUF+WERak3rN7VyJzxI4adgCulWLunidnjhl/bvTS2dbG3yc9Rk0eybEc9G/c2c8SkkYPSFhsjGGQqRuZzy9mzuPtTC7li8aSYkZ+IcONHZ4CCTx07mTdvPpV7r1nEN06fwQs3nsQjXzyWs+aO47EPdvHth1dy8yOrmDqqgJe+cTIvf/Nkzpwzlluf38BXHviAopxMzpozjsuOqmB9dTMrKhsAWF/dxK9f3Mhf39pGiz8A6B/bUyt3c/Ktr3LO796gvrUzol2BYIivPvABTR1dHDetjJ8/s45XN8TOkOqJYEjx6oZ9dAZCMft21rZx5d3vsmxHPfe+ub3X104lq3c10tDWxfnzx9PRFWLZjvp+v8ebm/ezbEc9W/e38vSqPTH7391aS26Wj8+fOJWt+1vZWZt80PjNTfs57/dv8syq4VeD4/k1ezn3tjf5T5wZecOJjU5FxPPnjQN0ZoLBwloEw4BTZ41m1Y/OjNkuIhw1uZSjJpfyy0sOZ1dDO3ub/MyfWBwenf7+yiMYX5LL3W9s48rFE8nLzuCC+RP46dPruPiPb5Ob5aOjK4QIKAX/+8JGDhs/gtoWP1tqWpk9bgSb97XwtX+u4C/XLKK+rZPnVlfz+Ae7WLqjnl9dNp+z547lkjve5pq/LKE4L4tZY4v44flzmD2+5xpD97y5lZ8/s54vnjKNm8+aRVNHF997bDVba1rYWddGhk84a85YXuxlXCMQDPHtR1bS0hHg1svmx7VouqPFHyA7w0d2Zvyx0usbaxCBm86YybOr9vDGpv0cN21U3GM7AyFuevhDLlwwPmmrRinFbS9vYlxxLgU5mfzxlS2cP298xFzzd7fWsnByKR89bAw/f2Y9r23cxyePnZLU9Z9drYXlgfd3cq7TEQ0X7ncmTzy6fBenHTZ0rMTeYjr+0w4bwy+f2xCOFwwGVggOEjIzfEwuK2ByWUHEdp9P+N65szl15mgOr9CL3Yrzs/jHtUezfGc9Nc1+ppTlc87h46isb+evb21jd2MH08oLuXLxJK45bgoPLa3iu4+t4szfvs7WmhZCCg4ZVcAPzpvNpUfpukL/uPZoHl1eRVV9O8+uruai29/i6mMm09zRxd5mP7PGFnHkpJGcdtjocAK/bftb+d8XNpKb5ePPb2zl0qMq+N8XNvD8mr2cPKOcw8aN4HMnTiUQVDy3ppoX1lRzxeJJdAZCZPok4QKcUEjx7UdW8ujyXWT4hMvufJu7P7Uw5rOJR0NbJ999bFV4pFyUm8nZc8dy+cKJLJxSGj7u9U01zB1fzKSyfI6cNJI3NtVw81mz4l7zr29v44kVu3lz035e/ubJFOdl8fiKXexp7GDiyHyOPqSU0UW5Eee8u7WOJdvr+fGFcyjKzeTGf37IS+v2csYcXTejrrWT9dXN3HTmeKaOKmBSaT6vbaxJSgiUUry0bi9ZGcKbm/dTWdfGxNL4xZiq6ttYvrOB46eVUVaY0+O1U83O2jbe2LSfotxMXlq3l+aOLopyeyfyfaG9M0hHVzBurKavbNzbTGFOJhUj85gxptBaBJbUc9yhkaPVxVNLWTy1NGJbWWEOv73iiJhzr1w8kfXVTby3tY4bTj2Uc+aNY+aYogj/bHlRDl84eRoAN54+g+88upJ739rGqMJsyotyeXdLLXe9vpUJJXl85vgpVIzM5543t5Kd6eOBzx/DlXe9y1V3v0d1Uwc3nzWLL54yLXxtpRSTSvN5ZnU1xx86ikvueBt/IMSiKaVcdfQkTp01OuLYHz+1lkeX7+IbTmzk+vuWcfKtrzKhJI8Tp4/iS6ccyqQy3fG1+AP84InVvLxuH4eUF7CnoYP9LX6uO+kQivOy2FLTwtMr9/DQ0ipuu/IILpg/nuaOLpbvbOD6k3VM5MTpo/j1SxupbfHHdJY1zX5+//JmDp9QzNo9TfzP8xsYmZ/F7a9sCR+TlSFcuGACN5x6KFNGFdDqD/CTp9YyuiiHyxdOJNMn/ObFTdz6/AaOnlpGcX4W7zl5rI45pBQR4eQZ5fxrWWVMhb2mji7W7m7i6Kml4e9r9a4m9jb5+dYZM/j1ixt5aGkl3zxjZvicUEjx1Ko9/O6ljWypaQXgo4eN5s+fXhT/n8vh/vd2MDI/m3MO1xZGe2eQoFIR62v2NLbzq+c3Utfq546rj+r1qvsHl+zEJ/CLj83jy/+3nOfX7A0PRvpCQ1snuVkZ4XY8u2oPQaU4b974iOO+eP8yVlY18uzXTmTMiNx4l+o1G/c2M31MISLCjDFFvNIH12p/YYXA0iMiwo8vnJv08aUF2fzpkwtp6wyQn63/xToDId7cXMPtr2zhp0+vCx/7P5fOY+6EYm48fQY/fmotJ80o5wsnRQadRYSzDx/LPW9s45q/vE9HV5Az54zl7S21fOavS7h8YQXfO2c2xflZ/OalTfz17e187oSpfOUjhyIiPP2VE3luzR4+rGzksQ928fCyKk6dNZoJJXm8umEfO+vaOH/+ePY2dTCxNI+7P7UwbD0BtF0U4JP3vM8tj6xkUmk+v35xI8GQCrslTp01mv99cSNn/OZ1zpyrU5kHQ4rSgmze31ZHe1eQ312xgPvf28k9b24DtLh+95zD2L6/jYeXVfLQ0iqeXbWHn3/scB5dvosNe5u5+1NuR/mzi+dy7V+X8sl73+MrH5nO/zy/gcKczPD6lWtPmMrjH+ziS/cv51/XH0tTe4B739rGfe/soNkf4KYzZ/LlUw8F4MW11fgEPnH0ZJbtqOdfS6v4+kdnkOETVu9q5HuPreLDqkbHxTeb6sYO/vT6Vl7ZsI95E4r5xkMfUlnfRlFuFlcumsgViyfx5qb9fO+x1WRn+DikvIAJJXlcesc77G5s5+sfncHCySN57INdPLhkJyGlV9d/59FV/Pry+T0GfFdWNfCrFzZy5KQSHlpaxUdmjeacw8cysTSPJ1bs6pMQtHcGufO1Ldz52hbmTijmgc8fw4bqZr7ywAcEQop3ttTyw/PnkJ3pY/WuRl7doIPx3/rXh/ztM4vpDIZo79QWQiikuOfNbby7tZZfXjqPUYU5vLe1lkeX7+L758+OEEKlFFX17VSMzGNDdTNnOhbezLFF/GtZFftb/IwqzKGm2c+jy6s4d964ASmda5POWQYUpRSVde20+APkZvk4pLwQ0D79x1fs5vTDxlCcH2vqf1jZwIW3v0VWhvD3zx7NsdPK8AeC/O6lTdz52hYyfMKc8cWsqGzg8oUV/PKSeXE7mL1NHdzx6hZe31hDTYuf0oJsfnXZfBZNKY051kt1Ywfn3vYGta2dZPiEn100lysWTwrvf3XDPv61rIqX1+3FHwjhEwmnIb/upEP47jmH0eIPcOkdb7N4ain/7/w5Ea6t6sYOvnT/MpbvbADgvz92OFd6rg/w8rq9XH/fMrqC2kL6xccOj7D0nl9TzRf+sYx5FcVsqG6mMxjinLnjCCnFs6ur+Z9L5nH5oomc/bs3KMrJ5KHrj+W51dVcf98yZo4pYta4Ip5auYeR+dncfNZMPnZkBRk+oTMQ4qzfvo5CL5SsrGvjtMNGs31/G2v3NHHL2bP4+9vbycnKoLmji9FFuYwvyeWVDTUcNWkk72/XxZ2yM3ycO28c3zh9Bo99sItfv7iRm86cyfUnTyPDJ+yobeXFtXtZvauRts4g3zpzJoU5mVzwh7do7wzQ1hVEKfjLNYs4ddZofvX8Bv746mae//pJTB9TFPOdra9u4pmVezhmWhnHTRuFUop3ttby7w938/waHXM6bloZb2+p5crFE1m6vZ6mji7Omzeee97cxnHTyrj3mkXc/MhKXl63jy+feii/fG49J80o58PKBpo6ujhxejn+riDvbavDJzCtvJDrT57Gdx9bhT8Q4srFk/jvjx0OaEvrR/9ew9/e2cGUsny217bx/fNmc+0JU3lz036uvuc9zj18HAU5GTz54W46ukKcNKOcv392cbf/m8nSXdI5KwSWYYFSiv96fDXHHzoq7HowrNndyJMrdvPyej1ivfWy+WSkIIHX21v28+N/r+W75xzGSTPKE7ZTRFBK0dDWRU2Ln0NGFYSnfpr98egMhPj9fzZRVpDNNcfHX+Px5qb9rN3TyKeOnRLXrXLr8+u56/WtfOyICr5w8iEcUl5IZyDEtX9bwhub9ofXkXzvnMP4/EmHEAop7n9vB0+t3MOKygYuWjCB755zWIwYv7JhH5/5yxIKsjO455pFHHNIGZ2BEF+6fxkvrduHT+CRLx7HvmY/X/jHMgB+dMEcPnXsZF7ftJ+9jR2cOWds+LqhkOJL9y/nuTXVjBmRw5SyAt7bpgVjXHEu7V1B2jqDjB2RS31rJ49+6ThKC7LZUtPKoikjEdHCce5tb9LRFeTjiyZy0oxyxozIZen2Op5fU82S7e5MrkuOrGBHbStLd9RTkJ3BRw4bwyePmcziqaX8/Jl13PX6VgD++plFnDJzNI8sq+JbD3/I0VNLWbK9ns8eP4XvnnMYX7xvOf9Zv48z545lUmkej3+wm4a2Tn54/hwqSvO49q9Lae8KMnfCCOZXlHD/ezv5yzWLmDm2iJ89s46nV+7hY0dMYEddG8t21PPEl49n/sQSmjq6uOyOd9jb3EEgqDhjzhhGFeZw1+tb+ce1izl6ahnff3w1FywYz/GHxp+U0BNWCCyWNKKjKxgjEm2dAe57dwdLttezq76de65ZGF7YaOhOpAD+uWQnc8YXhzPsgk7Z/sMn1jBrbFFYvH79wgYQ4caPTu/2eoFgiJfW7eWfSyqprG/ngvnjufSoCsaX5FHT7OfmR1by+sYa/vzphZySYLHcvqYObvvPJh58v5KApxDUjDGFXHpUBRfMn8Bf3trG3W9spbwohxs+Mp3LjqqI+HwCwRDf+teHTCrN5xueWMn97+3ge4+tJtMnvHHzqYwrziMQDNEZDIVdnqGQIqRUWOiXbq/j3x/u5ptnziQn08cFv3+Lrftb6Arqtn33nFlcd9K08HdirhMPfyDIaf/7GkW5WZQWZPHW5tqI83uLFQKLxTLsUErR7A8wIolZQU0dXWzf38ruhnZmjysOTwYw1LV2kp+d0evg9MPLqvAHglx19ORenWfYUN3Mb1/ayBGTSvjIrDEcOrqwV+c/sWIXX3twBZk+4ReXzDugwPigCYGInAX8DsgA/qyU+kXUfnH2nwO0AdcopZZ3d00rBBaLJV0IhRS/e3kTRx9SmnCdSrIMSmEaEckAbgdOB6qAJSLypFLKm/rybGC683c0cIfzaLFYLGmPzyfcePqMng880Puk8NqLgc1Kqa1KqU7gQeDCqGMuBP6uNO8CJSIyvJY5WiwWyzAnlUIwAaj0vK5ytvX2GETkOhFZKiJLa2p6n1zLYrFYLIlJpRDEmy4QHZBI5hiUUncppRYqpRaWl8eftmexWCyWvpFKIagCJnpeVwC7+3CMxWKxWFJIKoVgCTBdRKaKSDZwBfBk1DFPAp8SzTFAo1IqNt+uxWKxWFJGymYNKaUCInID8Dx6+ui9Sqk1InK9s/9O4Bn01NHN6Omjn0lVeywWi8USn5QmnVNKPYPu7L3b7vQ8V8CXU9kGi8VisXSPrVBmsVgsac6wSzEhIjXAjj6ePgrY34/NSQW2jf2DbWP/YNt44AyV9k1WSsWddjnshOBAEJGliZZYDxVsG/sH28b+wbbxwBnq7QPrGrJYLJa0xwqBxWKxpDnpJgR3DXYDksC2sX+wbewfbBsPnKHevvSKEVgsFosllnSzCCwWi8UShRUCi8ViSXPSRghE5CwR2SAim0XklsFuD4CITBSRV0RknYisEZGvOdtLReRFEdnkPI4c5HZmiMgHIvLUEG1fiYg8LCLrnc/y2CHYxhud73i1iDwgIrmD3UYRuVdE9onIas+2hG0Ske84v58NInLmILbxVue7Xikij4lIyVBro2fft0REicgoz7YBb2NPpIUQeKqlnQ3MBq4UkdmD2yoAAsA3lVKHAccAX3badQvwslJqOvCy83ow+RqwzvN6qLXvd8BzSqlZwHx0W4dMG0VkAvBVYKFSai4699YVQ6CNfwXOitoWt03O/+UVwBznnD86v6vBaOOLwFyl1DxgI/CdIdhGRGQiukLjTs+2wWpjt6SFEJBctbQBRym1x9RoVko1ozuwCei2/c057G/ARYPSQEBEKoBzgT97Ng+l9o0ATgLuAVBKdSqlGhhCbXTIBPJEJBPIR6dbH9Q2KqVeB+qiNidq04XAg0opv1JqGzpR5OLBaKNS6gWlVMB5+S46ff2QaqPDb4BvE1ljZVDa2BPpIgRJVUIbTERkCnAE8B4wxqTjdh5HD2LTfov+Zw55tg2l9h0C1AB/cdxXfxaRgqHURqXULuBX6JHhHnS69ReGUhs9JGrTUP0NfRZ41nk+ZNooIhcAu5RSH0btGjJt9JIuQpBUJbTBQkQKgUeAryulmga7PQYROQ/Yp5RaNtht6YZM4EjgDqXUEUArg++qisDxs18ITAXGAwUicvXgtqrXDLnfkIh8D+1evd9sinPYgLdRRPKB7wE/iLc7zrZB74vSRQiGbCU0EclCi8D9SqlHnc17RWScs38csG+Qmnc8cIGIbEe70z4iIvcNofaB/m6rlFLvOa8fRgvDUGrjR4FtSqkapVQX8Chw3BBroyFRm4bUb0hEPg2cB1yl3MVQQ6WN09Ci/6Hz26kAlovIWIZOGyNIFyFIplragCMigvZtr1NK/dqz60ng087zTwNPDHTbAJRS31FKVSilpqA/s/8opa4eKu0DUEpVA5UiMtPZdBqwliHURrRL6BgRyXe+89PQ8aCh1EZDojY9CVwhIjkiMhWYDrw/CO1DRM4CbgYuUEq1eXYNiTYqpVYppUYrpaY4v50q4Ejnf3VItDEGpVRa/KEroW0EtgDfG+z2OG06AW0WrgRWOH/nAGXoGRubnMfSIdDWU4CnnOdDqn3AAmCp8zk+Dowcgm38EbAeWA38A8gZ7DYCD6BjFl3ozura7tqEdndsATYAZw9iGzej/ezmN3PnUGtj1P7twKjBbGNPfzbFhMVisaQ56eIaslgsFksCrBBYLBZLmmOFwGKxWNIcKwQWi8WS5lghsFgsljTHCoHFMoCIyCkmi6vFMlSwQmCxWCxpjhUCiyUOInK1iLwvIitE5E9OTYYWEflfEVkuIi+LSLlz7AIRedeTH3+ks/1QEXlJRD50zpnmXL5Q3PoJ9zurjS2WQcMKgcUShYgcBnwcOF4ptQAIAlcBBcBypdSRwGvAD51T/g7crHR+/FWe7fcDtyul5qNzC+1xth8BfB1dG+MQdE4ni2XQyBzsBlgsQ5DTgKOAJc5gPQ+dfC0E/NM55j7gUREpBkqUUq852/8G/EtEioAJSqnHAJRSHQDO9d5XSlU5r1cAU4A3U/6uLJYEWCGwWGIR4G9Kqe9EbBT5ftRx3eVn6c7d4/c8D2J/h5ZBxrqGLJZYXgYuFZHREK7jOxn9e7nUOeYTwJtKqUagXkROdLZ/EnhN6boSVSJykXONHCdPvcUy5LAjEYslCqXUWhH5L+AFEfGhs0p+GV30Zo6ILAMa0XEE0Oma73Q6+q3AZ5ztnwT+JCI/dq5x2QC+DYslaWz2UYslSUSkRSlVONjtsFj6G+saslgsljTHWgQWi8WS5liLwGKxWNIcKwQWi8WS5lghsFgsljTHCoHFYrGkOVYILBaLJc35/+dRGSUWZ6sdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypertuning of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "a = StandardScaler()\n",
    "a.fit(X)\n",
    "X_standardized = a.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.874674e-17</td>\n",
       "      <td>5.110891e-17</td>\n",
       "      <td>-9.019220e-17</td>\n",
       "      <td>2.594099e-16</td>\n",
       "      <td>6.442300e-17</td>\n",
       "      <td>-8.718579e-17</td>\n",
       "      <td>-7.816657e-17</td>\n",
       "      <td>6.485249e-17</td>\n",
       "      <td>4.724353e-18</td>\n",
       "      <td>-4.790924e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>7.179943e-16</td>\n",
       "      <td>-1.933764e-16</td>\n",
       "      <td>-2.260174e-17</td>\n",
       "      <td>1.352883e-17</td>\n",
       "      <td>1.169277e-16</td>\n",
       "      <td>2.265542e-16</td>\n",
       "      <td>-2.596515e-16</td>\n",
       "      <td>1.443075e-16</td>\n",
       "      <td>6.253326e-16</td>\n",
       "      <td>4.024290e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.317959e+00</td>\n",
       "      <td>-1.423121e+00</td>\n",
       "      <td>-2.755520e+00</td>\n",
       "      <td>-2.134531e+00</td>\n",
       "      <td>-2.119754e+00</td>\n",
       "      <td>-2.133725e+00</td>\n",
       "      <td>-2.036890e+00</td>\n",
       "      <td>-1.713964e+00</td>\n",
       "      <td>-2.004018e+00</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.089076e+00</td>\n",
       "      <td>-9.031536e-01</td>\n",
       "      <td>-5.025653e-01</td>\n",
       "      <td>-8.010724e-01</td>\n",
       "      <td>-7.605602e-01</td>\n",
       "      <td>-6.928003e-01</td>\n",
       "      <td>-7.181571e-01</td>\n",
       "      <td>-7.060079e-01</td>\n",
       "      <td>-7.499909e-01</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.533922e-02</td>\n",
       "      <td>1.367805e-01</td>\n",
       "      <td>1.039993e-01</td>\n",
       "      <td>1.234588e-01</td>\n",
       "      <td>1.959092e-01</td>\n",
       "      <td>-4.438437e-02</td>\n",
       "      <td>4.755898e-02</td>\n",
       "      <td>-1.390326e-01</td>\n",
       "      <td>2.425585e-03</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.199754e+00</td>\n",
       "      <td>6.567476e-01</td>\n",
       "      <td>6.672378e-01</td>\n",
       "      <td>8.168572e-01</td>\n",
       "      <td>7.999952e-01</td>\n",
       "      <td>6.400547e-01</td>\n",
       "      <td>7.494654e-01</td>\n",
       "      <td>5.539372e-01</td>\n",
       "      <td>5.040366e-01</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.199754e+00</td>\n",
       "      <td>1.696682e+00</td>\n",
       "      <td>1.793715e+00</td>\n",
       "      <td>1.670271e+00</td>\n",
       "      <td>1.538322e+00</td>\n",
       "      <td>2.117002e+00</td>\n",
       "      <td>2.025659e+00</td>\n",
       "      <td>2.947833e+00</td>\n",
       "      <td>3.012092e+00</td>\n",
       "      <td>1.354679e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.512952e+00</td>\n",
       "      <td>4.984977e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>3.893103e+00</td>\n",
       "      <td>5.423261e+00</td>\n",
       "      <td>2.928152e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>2.271563e+01</td>\n",
       "      <td>5.785038e+00</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -4.874674e-17  5.110891e-17 -9.019220e-17  2.594099e-16  6.442300e-17   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.317959e+00 -1.423121e+00 -2.755520e+00 -2.134531e+00 -2.119754e+00   \n",
       "25%   -1.089076e+00 -9.031536e-01 -5.025653e-01 -8.010724e-01 -7.605602e-01   \n",
       "50%    5.533922e-02  1.367805e-01  1.039993e-01  1.234588e-01  1.959092e-01   \n",
       "75%    1.199754e+00  6.567476e-01  6.672378e-01  8.168572e-01  7.999952e-01   \n",
       "max    1.199754e+00  1.696682e+00  1.793715e+00  1.670271e+00  1.538322e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -8.718579e-17 -7.816657e-17  6.485249e-17  4.724353e-18 -4.790924e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -2.133725e+00 -2.036890e+00 -1.713964e+00 -2.004018e+00 -1.100649e-01   \n",
       "25%   -6.928003e-01 -7.181571e-01 -7.060079e-01 -7.499909e-01 -1.100649e-01   \n",
       "50%   -4.438437e-02  4.755898e-02 -1.390326e-01  2.425585e-03 -1.100649e-01   \n",
       "75%    6.400547e-01  7.494654e-01  5.539372e-01  5.040366e-01 -1.100649e-01   \n",
       "max    2.117002e+00  2.025659e+00  2.947833e+00  3.012092e+00  1.354679e+01   \n",
       "\n",
       "       ...            20            21            22            23  \\\n",
       "count  ...  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   ...  7.179943e-16 -1.933764e-16 -2.260174e-17  1.352883e-17   \n",
       "std    ...  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "25%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "50%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "75%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "max    ...  7.512952e+00  4.984977e+00  1.604681e+01  3.893103e+00   \n",
       "\n",
       "                 24            25            26            27            28  \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   1.169277e-16  2.265542e-16 -2.596515e-16  1.443075e-16  6.253326e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "25%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "50%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "75%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "max    5.423261e+00  2.928152e+00  1.604681e+01  2.271563e+01  5.785038e+00   \n",
       "\n",
       "                 29  \n",
       "count  5.170000e+02  \n",
       "mean   4.024290e-16  \n",
       "std    1.000969e+00  \n",
       "min   -7.060812e-01  \n",
       "25%   -7.060812e-01  \n",
       "50%   -7.060812e-01  \n",
       "75%    1.416268e+00  \n",
       "max    1.416268e+00  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_standardized).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=30, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    \n",
    "    adam=Adam(learning_rate=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15860\\120257800.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 1/5; 1/9] END .....batch_size=10, epochs=10;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 2/5; 1/9] END .....batch_size=10, epochs=10;, score=0.942 total time=   1.5s\n",
      "[CV 3/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 3/5; 1/9] END .....batch_size=10, epochs=10;, score=0.981 total time=   1.5s\n",
      "[CV 4/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 4/5; 1/9] END .....batch_size=10, epochs=10;, score=0.932 total time=   1.8s\n",
      "[CV 5/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 5/5; 1/9] END .....batch_size=10, epochs=10;, score=0.913 total time=   2.0s\n",
      "[CV 1/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 1/5; 2/9] END .....batch_size=10, epochs=50;, score=1.000 total time=   4.6s\n",
      "[CV 2/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 2/5; 2/9] END .....batch_size=10, epochs=50;, score=0.942 total time=   4.0s\n",
      "[CV 3/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 3/5; 2/9] END .....batch_size=10, epochs=50;, score=0.971 total time=   4.1s\n",
      "[CV 4/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 4/5; 2/9] END .....batch_size=10, epochs=50;, score=0.951 total time=   5.5s\n",
      "[CV 5/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 5/5; 2/9] END .....batch_size=10, epochs=50;, score=0.922 total time=   4.2s\n",
      "[CV 1/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 1/5; 3/9] END ....batch_size=10, epochs=100;, score=1.000 total time=   7.7s\n",
      "[CV 2/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 2/5; 3/9] END ....batch_size=10, epochs=100;, score=0.913 total time=   7.9s\n",
      "[CV 3/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 3/5; 3/9] END ....batch_size=10, epochs=100;, score=0.981 total time=   7.4s\n",
      "[CV 4/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 4/5; 3/9] END ....batch_size=10, epochs=100;, score=0.942 total time=   8.0s\n",
      "[CV 5/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 5/5; 3/9] END ....batch_size=10, epochs=100;, score=0.922 total time=   7.5s\n",
      "[CV 1/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 1/5; 4/9] END .....batch_size=20, epochs=10;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 2/5; 4/9] END .....batch_size=20, epochs=10;, score=0.942 total time=   1.8s\n",
      "[CV 3/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 3/5; 4/9] END .....batch_size=20, epochs=10;, score=0.981 total time=   1.2s\n",
      "[CV 4/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 4/5; 4/9] END .....batch_size=20, epochs=10;, score=0.951 total time=   1.2s\n",
      "[CV 5/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 5/5; 4/9] END .....batch_size=20, epochs=10;, score=0.913 total time=   1.2s\n",
      "[CV 1/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 1/5; 5/9] END .....batch_size=20, epochs=50;, score=1.000 total time=   2.8s\n",
      "[CV 2/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 2/5; 5/9] END .....batch_size=20, epochs=50;, score=0.933 total time=   2.6s\n",
      "[CV 3/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 3/5; 5/9] END .....batch_size=20, epochs=50;, score=0.981 total time=   2.7s\n",
      "[CV 4/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 4/5; 5/9] END .....batch_size=20, epochs=50;, score=0.942 total time=   3.2s\n",
      "[CV 5/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 5/5; 5/9] END .....batch_size=20, epochs=50;, score=0.922 total time=   2.8s\n",
      "[CV 1/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 1/5; 6/9] END ....batch_size=20, epochs=100;, score=1.000 total time=   4.7s\n",
      "[CV 2/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 2/5; 6/9] END ....batch_size=20, epochs=100;, score=0.933 total time=   4.2s\n",
      "[CV 3/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 3/5; 6/9] END ....batch_size=20, epochs=100;, score=0.981 total time=   4.6s\n",
      "[CV 4/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 4/5; 6/9] END ....batch_size=20, epochs=100;, score=0.942 total time=   4.2s\n",
      "[CV 5/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 5/5; 6/9] END ....batch_size=20, epochs=100;, score=0.874 total time=   4.2s\n",
      "[CV 1/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 1/5; 7/9] END .....batch_size=40, epochs=10;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 2/5; 7/9] END .....batch_size=40, epochs=10;, score=0.981 total time=   1.3s\n",
      "[CV 3/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 3/5; 7/9] END .....batch_size=40, epochs=10;, score=0.951 total time=   1.1s\n",
      "[CV 4/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 4/5; 7/9] END .....batch_size=40, epochs=10;, score=0.942 total time=   1.5s\n",
      "[CV 5/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 5/5; 7/9] END .....batch_size=40, epochs=10;, score=0.883 total time=   1.6s\n",
      "[CV 1/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 1/5; 8/9] END .....batch_size=40, epochs=50;, score=1.000 total time=   1.8s\n",
      "[CV 2/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 2/5; 8/9] END .....batch_size=40, epochs=50;, score=0.952 total time=   1.9s\n",
      "[CV 3/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 3/5; 8/9] END .....batch_size=40, epochs=50;, score=0.981 total time=   2.1s\n",
      "[CV 4/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 4/5; 8/9] END .....batch_size=40, epochs=50;, score=0.942 total time=   1.8s\n",
      "[CV 5/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 5/5; 8/9] END .....batch_size=40, epochs=50;, score=0.932 total time=   1.8s\n",
      "[CV 1/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 1/5; 9/9] END ....batch_size=40, epochs=100;, score=1.000 total time=   2.8s\n",
      "[CV 2/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 2/5; 9/9] END ....batch_size=40, epochs=100;, score=0.933 total time=   3.3s\n",
      "[CV 3/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 3/5; 9/9] END ....batch_size=40, epochs=100;, score=0.981 total time=   2.7s\n",
      "[CV 4/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 4/5; 9/9] END ....batch_size=40, epochs=100;, score=0.951 total time=   3.0s\n",
      "[CV 5/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 5/5; 9/9] END ....batch_size=40, epochs=100;, score=0.922 total time=   2.8s\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "# Define the grid search parameters\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9612583994865418, using {'batch_size': 40, 'epochs': 50}\n",
      "0.9535100936889649,0.0321017863796702 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.9573935747146607,0.026417063460676158 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.9516243457794189,0.0334391492541235 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.9573935866355896,0.030398747709849037 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.9554704904556275,0.029728586807058317 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.945761752128601,0.04363863415688332 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.9514936447143555,0.039821372349041255 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.9612583994865418,0.02528215974732713 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.9574122428894043,0.02907881295327616 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "def create_model(learning_rate,dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4,input_dim = 30,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15860\\384741517.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 1/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=1.000 total time=   1.5s\n",
      "[CV 2/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.952 total time=   1.1s\n",
      "[CV 3/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.524 total time=   1.1s\n",
      "[CV 4/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.680 total time=   1.3s\n",
      "[CV 5/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.699 total time=   1.4s\n",
      "[CV 1/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.942 total time=   1.5s\n",
      "[CV 3/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.961 total time=   1.1s\n",
      "[CV 4/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.942 total time=   1.1s\n",
      "[CV 5/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.932 total time=   1.1s\n",
      "[CV 1/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.942 total time=   1.4s\n",
      "[CV 3/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.971 total time=   1.1s\n",
      "[CV 4/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.942 total time=   1.1s\n",
      "[CV 5/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.922 total time=   1.1s\n",
      "[CV 1/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=1.000 total time=   1.2s\n",
      "[CV 2/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.875 total time=   1.2s\n",
      "[CV 3/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.524 total time=   1.8s\n",
      "[CV 4/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.680 total time=   1.7s\n",
      "[CV 5/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.689 total time=   1.2s\n",
      "[CV 1/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=1.000 total time=   1.2s\n",
      "[CV 2/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.904 total time=   1.1s\n",
      "[CV 3/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.932 total time=   1.4s\n",
      "[CV 4/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.961 total time=   1.2s\n",
      "[CV 5/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.903 total time=   1.2s\n",
      "[CV 1/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=1.000 total time=   1.3s\n",
      "[CV 2/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.990 total time=   1.3s\n",
      "[CV 3/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.971 total time=   1.2s\n",
      "[CV 4/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.893 total time=   1.6s\n",
      "[CV 5/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.913 total time=   1.7s\n",
      "[CV 1/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=1.000 total time=   1.4s\n",
      "[CV 2/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.750 total time=   1.4s\n",
      "[CV 3/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.680 total time=   1.5s\n",
      "[CV 5/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.699 total time=   1.2s\n",
      "[CV 1/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=1.000 total time=   1.2s\n",
      "[CV 2/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.971 total time=   1.2s\n",
      "[CV 3/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.981 total time=   1.2s\n",
      "[CV 4/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.942 total time=   1.2s\n",
      "[CV 5/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.903 total time=   1.5s\n",
      "[CV 1/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.952 total time=   1.5s\n",
      "[CV 3/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.961 total time=   1.2s\n",
      "[CV 4/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.922 total time=   1.2s\n",
      "[CV 5/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.922 total time=   1.4s\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9651792287826538, using {'batch_size': 10, 'epochs': 100}\n",
      "0.957374906539917,0.02343978202437491 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.9495892405509949,0.03807347750067746 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.9651792287826538,0.024846008839100615 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.9554518342018128,0.02977944871198138 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.9573375701904296,0.03398930150563457 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.9419342875480652,0.04008619180888525 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.9379760980606079,0.035072296454388203 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.9477408528327942,0.03749707869161704 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.9651605725288391,0.02491411456685331 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning of Hyperparameters:- Activation Function and Kernel Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4,input_dim = 30,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15860\\2864657069.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 1/5; 1/12] END activation_function=softmax, init=uniform;, score=1.000 total time=   1.3s\n",
      "[CV 2/5; 1/12] START activation_function=softmax, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/12] END activation_function=softmax, init=uniform;, score=0.250 total time=   1.2s\n",
      "[CV 3/5; 1/12] START activation_function=softmax, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/12] END activation_function=softmax, init=uniform;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 1/12] START activation_function=softmax, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/12] END activation_function=softmax, init=uniform;, score=0.680 total time=   1.2s\n",
      "[CV 5/5; 1/12] START activation_function=softmax, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/12] END activation_function=softmax, init=uniform;, score=0.699 total time=   1.5s\n",
      "[CV 1/5; 2/12] START activation_function=softmax, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/12] END activation_function=softmax, init=normal;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 2/12] START activation_function=softmax, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/12] END activation_function=softmax, init=normal;, score=0.750 total time=   1.8s\n",
      "[CV 3/5; 2/12] START activation_function=softmax, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/12] END activation_function=softmax, init=normal;, score=0.524 total time=   1.4s\n",
      "[CV 4/5; 2/12] START activation_function=softmax, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 2/12] END activation_function=softmax, init=normal;, score=0.680 total time=   1.2s\n",
      "[CV 5/5; 2/12] START activation_function=softmax, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/12] END activation_function=softmax, init=normal;, score=0.699 total time=   1.5s\n",
      "[CV 1/5; 3/12] START activation_function=softmax, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/12] END activation_function=softmax, init=zero;, score=1.000 total time=   1.3s\n",
      "[CV 2/5; 3/12] START activation_function=softmax, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/12] END activation_function=softmax, init=zero;, score=0.750 total time=   1.3s\n",
      "[CV 3/5; 3/12] START activation_function=softmax, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/12] END activation_function=softmax, init=zero;, score=0.524 total time=   1.4s\n",
      "[CV 4/5; 3/12] START activation_function=softmax, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/12] END activation_function=softmax, init=zero;, score=0.680 total time=   1.5s\n",
      "[CV 5/5; 3/12] START activation_function=softmax, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/12] END activation_function=softmax, init=zero;, score=0.699 total time=   1.2s\n",
      "[CV 1/5; 4/12] START activation_function=relu, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/12] END activation_function=relu, init=uniform;, score=1.000 total time=   1.5s\n",
      "[CV 2/5; 4/12] START activation_function=relu, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/12] END activation_function=relu, init=uniform;, score=0.750 total time=   1.7s\n",
      "[CV 3/5; 4/12] START activation_function=relu, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/12] END activation_function=relu, init=uniform;, score=0.631 total time=   1.6s\n",
      "[CV 4/5; 4/12] START activation_function=relu, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/12] END activation_function=relu, init=uniform;, score=0.680 total time=   1.2s\n",
      "[CV 5/5; 4/12] START activation_function=relu, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 4/12] END activation_function=relu, init=uniform;, score=0.767 total time=   1.2s\n",
      "[CV 1/5; 5/12] START activation_function=relu, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/12] END activation_function=relu, init=normal;, score=1.000 total time=   1.4s\n",
      "[CV 2/5; 5/12] START activation_function=relu, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/12] END activation_function=relu, init=normal;, score=0.750 total time=   1.2s\n",
      "[CV 3/5; 5/12] START activation_function=relu, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/12] END activation_function=relu, init=normal;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 5/12] START activation_function=relu, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 5/12] END activation_function=relu, init=normal;, score=0.680 total time=   1.1s\n",
      "[CV 5/5; 5/12] START activation_function=relu, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/12] END activation_function=relu, init=normal;, score=0.699 total time=   1.2s\n",
      "[CV 1/5; 6/12] START activation_function=relu, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/12] END activation_function=relu, init=zero;, score=1.000 total time=   1.2s\n",
      "[CV 2/5; 6/12] START activation_function=relu, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/12] END activation_function=relu, init=zero;, score=0.750 total time=   1.4s\n",
      "[CV 3/5; 6/12] START activation_function=relu, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/12] END activation_function=relu, init=zero;, score=0.524 total time=   1.7s\n",
      "[CV 4/5; 6/12] START activation_function=relu, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/12] END activation_function=relu, init=zero;, score=0.680 total time=   1.8s\n",
      "[CV 5/5; 6/12] START activation_function=relu, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 6/12] END activation_function=relu, init=zero;, score=0.699 total time=   1.2s\n",
      "[CV 1/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 7/12] END activation_function=tanh, init=uniform;, score=0.990 total time=   1.2s\n",
      "[CV 2/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 7/12] END activation_function=tanh, init=uniform;, score=0.808 total time=   1.2s\n",
      "[CV 3/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 7/12] END activation_function=tanh, init=uniform;, score=0.757 total time=   1.4s\n",
      "[CV 4/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 7/12] END activation_function=tanh, init=uniform;, score=0.825 total time=   1.2s\n",
      "[CV 5/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 7/12] END activation_function=tanh, init=uniform;, score=0.816 total time=   1.3s\n",
      "[CV 1/5; 8/12] START activation_function=tanh, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 8/12] END activation_function=tanh, init=normal;, score=1.000 total time=   1.2s\n",
      "[CV 2/5; 8/12] START activation_function=tanh, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 8/12] END activation_function=tanh, init=normal;, score=0.769 total time=   1.2s\n",
      "[CV 3/5; 8/12] START activation_function=tanh, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/12] END activation_function=tanh, init=normal;, score=0.786 total time=   1.2s\n",
      "[CV 4/5; 8/12] START activation_function=tanh, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 8/12] END activation_function=tanh, init=normal;, score=0.796 total time=   1.7s\n",
      "[CV 5/5; 8/12] START activation_function=tanh, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 8/12] END activation_function=tanh, init=normal;, score=0.786 total time=   1.8s\n",
      "[CV 1/5; 9/12] START activation_function=tanh, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/12] END activation_function=tanh, init=zero;, score=1.000 total time=   1.3s\n",
      "[CV 2/5; 9/12] START activation_function=tanh, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/12] END activation_function=tanh, init=zero;, score=0.750 total time=   1.3s\n",
      "[CV 3/5; 9/12] START activation_function=tanh, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/12] END activation_function=tanh, init=zero;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 9/12] START activation_function=tanh, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/12] END activation_function=tanh, init=zero;, score=0.680 total time=   1.4s\n",
      "[CV 5/5; 9/12] START activation_function=tanh, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 9/12] END activation_function=tanh, init=zero;, score=0.699 total time=   1.2s\n",
      "[CV 1/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 10/12] END activation_function=linear, init=uniform;, score=0.981 total time=   1.2s\n",
      "[CV 2/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 10/12] END activation_function=linear, init=uniform;, score=0.779 total time=   1.4s\n",
      "[CV 3/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 10/12] END activation_function=linear, init=uniform;, score=0.786 total time=   1.2s\n",
      "[CV 4/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 10/12] END activation_function=linear, init=uniform;, score=0.864 total time=   1.4s\n",
      "[CV 5/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 10/12] END activation_function=linear, init=uniform;, score=0.806 total time=   1.4s\n",
      "[CV 1/5; 11/12] START activation_function=linear, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/12] END activation_function=linear, init=normal;, score=0.990 total time=   1.8s\n",
      "[CV 2/5; 11/12] START activation_function=linear, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 11/12] END activation_function=linear, init=normal;, score=0.837 total time=   1.2s\n",
      "[CV 3/5; 11/12] START activation_function=linear, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 11/12] END activation_function=linear, init=normal;, score=0.728 total time=   1.3s\n",
      "[CV 4/5; 11/12] START activation_function=linear, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 11/12] END activation_function=linear, init=normal;, score=0.883 total time=   1.5s\n",
      "[CV 5/5; 11/12] START activation_function=linear, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 11/12] END activation_function=linear, init=normal;, score=0.816 total time=   1.2s\n",
      "[CV 1/5; 12/12] START activation_function=linear, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 12/12] END activation_function=linear, init=zero;, score=1.000 total time=   1.2s\n",
      "[CV 2/5; 12/12] START activation_function=linear, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 12/12] END activation_function=linear, init=zero;, score=0.750 total time=   1.3s\n",
      "[CV 3/5; 12/12] START activation_function=linear, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 12/12] END activation_function=linear, init=zero;, score=0.524 total time=   1.4s\n",
      "[CV 4/5; 12/12] START activation_function=linear, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 12/12] END activation_function=linear, init=zero;, score=0.680 total time=   1.6s\n",
      "[CV 5/5; 12/12] START activation_function=linear, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 12/12] END activation_function=linear, init=zero;, score=0.699 total time=   1.2s\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(activation_function = activation_function,init = init)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.8508215069770813, using {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.6305825233459472,0.24482772813004766 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
      "0.7655339717864991,0.12702874437720252 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'zero'}\n",
      "0.8392270326614379,0.07913917723066699 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
      "0.8276325702667237,0.08661816074268408 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
      "0.8431852102279663,0.07499975413793118 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.8508215069770813,0.08607164923413059 with: {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning of Hyperparameter :-Number of Neurons in activation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 30,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15860\\4114978605.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 1/5; 1/9] END .........neuron1=4, neuron2=2;, score=1.000 total time=   1.9s\n",
      "[CV 2/5; 1/9] START neuron1=4, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.750 total time=   1.4s\n",
      "[CV 3/5; 1/9] START neuron1=4, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.641 total time=   1.3s\n",
      "[CV 4/5; 1/9] START neuron1=4, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.718 total time=   1.2s\n",
      "[CV 5/5; 1/9] START neuron1=4, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.748 total time=   1.2s\n",
      "[CV 1/5; 2/9] START neuron1=4, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/9] END .........neuron1=4, neuron2=4;, score=1.000 total time=   1.5s\n",
      "[CV 2/5; 2/9] START neuron1=4, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.750 total time=   1.4s\n",
      "[CV 3/5; 2/9] START neuron1=4, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.641 total time=   1.3s\n",
      "[CV 4/5; 2/9] START neuron1=4, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.757 total time=   1.6s\n",
      "[CV 5/5; 2/9] START neuron1=4, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.748 total time=   1.8s\n",
      "[CV 1/5; 3/9] START neuron1=4, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/9] END .........neuron1=4, neuron2=8;, score=1.000 total time=   1.2s\n",
      "[CV 2/5; 3/9] START neuron1=4, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.750 total time=   1.5s\n",
      "[CV 3/5; 3/9] START neuron1=4, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.709 total time=   1.2s\n",
      "[CV 4/5; 3/9] START neuron1=4, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.806 total time=   1.2s\n",
      "[CV 5/5; 3/9] START neuron1=4, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.738 total time=   1.2s\n",
      "[CV 1/5; 4/9] START neuron1=8, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.990 total time=   1.2s\n",
      "[CV 2/5; 4/9] START neuron1=8, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.798 total time=   1.4s\n",
      "[CV 3/5; 4/9] START neuron1=8, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.748 total time=   1.2s\n",
      "[CV 4/5; 4/9] START neuron1=8, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.835 total time=   2.6s\n",
      "[CV 5/5; 4/9] START neuron1=8, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.748 total time=   2.1s\n",
      "[CV 1/5; 5/9] START neuron1=8, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/9] END .........neuron1=8, neuron2=4;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 5/9] START neuron1=8, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.817 total time=   1.8s\n",
      "[CV 3/5; 5/9] START neuron1=8, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.767 total time=   1.6s\n",
      "[CV 4/5; 5/9] START neuron1=8, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.825 total time=   1.5s\n",
      "[CV 5/5; 5/9] START neuron1=8, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.796 total time=   1.5s\n",
      "[CV 1/5; 6/9] START neuron1=8, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/9] END .........neuron1=8, neuron2=8;, score=1.000 total time=   1.5s\n",
      "[CV 2/5; 6/9] START neuron1=8, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.817 total time=   1.4s\n",
      "[CV 3/5; 6/9] START neuron1=8, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.786 total time=   1.9s\n",
      "[CV 4/5; 6/9] START neuron1=8, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.845 total time=   2.1s\n",
      "[CV 5/5; 6/9] START neuron1=8, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.825 total time=   1.6s\n",
      "[CV 1/5; 7/9] START neuron1=16, neuron2=2.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.981 total time=   1.5s\n",
      "[CV 2/5; 7/9] START neuron1=16, neuron2=2.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.827 total time=   1.5s\n",
      "[CV 3/5; 7/9] START neuron1=16, neuron2=2.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.796 total time=   1.9s\n",
      "[CV 4/5; 7/9] START neuron1=16, neuron2=2.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.903 total time=   1.4s\n",
      "[CV 5/5; 7/9] START neuron1=16, neuron2=2.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.835 total time=   1.3s\n",
      "[CV 1/5; 8/9] START neuron1=16, neuron2=4.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.981 total time=   1.2s\n",
      "[CV 2/5; 8/9] START neuron1=16, neuron2=4.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.817 total time=   1.2s\n",
      "[CV 3/5; 8/9] START neuron1=16, neuron2=4.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.874 total time=   1.7s\n",
      "[CV 4/5; 8/9] START neuron1=16, neuron2=4.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.864 total time=   2.1s\n",
      "[CV 5/5; 8/9] START neuron1=16, neuron2=4.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.883 total time=   1.2s\n",
      "[CV 1/5; 9/9] START neuron1=16, neuron2=8.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/9] END ........neuron1=16, neuron2=8;, score=1.000 total time=   1.2s\n",
      "[CV 2/5; 9/9] START neuron1=16, neuron2=8.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.894 total time=   1.2s\n",
      "[CV 3/5; 9/9] START neuron1=16, neuron2=8.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.874 total time=   1.2s\n",
      "[CV 4/5; 9/9] START neuron1=16, neuron2=8.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.942 total time=   1.2s\n",
      "[CV 5/5; 9/9] START neuron1=16, neuron2=8.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.913 total time=   1.6s\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'neuron1': 4, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model with optimum values of Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16,input_dim = 30,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'linear'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15860\\792720346.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step\n",
      "0.9864603481624759\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 100)\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "model.fit(X_standardized,Y)\n",
    "\n",
    "# Predicting using trained model\n",
    "\n",
    "y_predict = model.predict(X_standardized)\n",
    "\n",
    "# Printing the metrics\n",
    "print(accuracy_score(Y.round(),y_predict.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
