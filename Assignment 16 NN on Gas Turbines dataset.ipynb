{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.11.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Downloading tensorflow_intel-2.11.0-cp39-cp39-win_amd64.whl (266.3 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-15.0.6.1-py2.py3-none-win_amd64.whl (23.2 MB)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.42.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (61.2.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.29.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.6.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.1.4-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.1.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.27.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.2.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.4)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 flatbuffers-23.1.4 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 libclang-15.0.6.1 oauthlib-3.2.2 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.29.0 termcolor-2.2.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_turbines=pd.read_csv(\"D:/Work/Data Science and Analyst Course/ExcelR/Data Science/Assignments/16_Neural Networks/gas_turbines.csv\")\n",
    "df_turbines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEY</th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114.70</td>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114.72</td>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114.71</td>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114.72</td>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114.72</td>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>111.61</td>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>111.78</td>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>110.19</td>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>110.74</td>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>111.58</td>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          TEY      AT      AP      AH\n",
       "0      114.70  6.8594  1007.9  96.799\n",
       "1      114.72  6.7850  1008.4  97.118\n",
       "2      114.71  6.8977  1008.8  95.939\n",
       "3      114.72  7.0569  1009.2  95.249\n",
       "4      114.72  7.3978  1009.7  95.150\n",
       "...       ...     ...     ...     ...\n",
       "15034  111.61  9.0301  1005.6  98.460\n",
       "15035  111.78  7.8879  1005.9  99.093\n",
       "15036  110.19  7.2647  1006.3  99.496\n",
       "15037  110.74  7.0060  1006.8  99.008\n",
       "15038  111.58  6.9279  1007.2  97.533\n",
       "\n",
       "[15039 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Problem statement: predicting turbine energy yield (TEY) using ambient variables as features.\n",
    "### So we will keep only related columns\n",
    "df_turbines=df_turbines.iloc[:,[7,0,1,2]]\n",
    "df_turbines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15039, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_turbines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEY</th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.00000</td>\n",
       "      <td>15039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>134.188464</td>\n",
       "      <td>17.764381</td>\n",
       "      <td>1013.19924</td>\n",
       "      <td>79.124174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.829717</td>\n",
       "      <td>7.574323</td>\n",
       "      <td>6.41076</td>\n",
       "      <td>13.793439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100.170000</td>\n",
       "      <td>0.522300</td>\n",
       "      <td>985.85000</td>\n",
       "      <td>30.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>127.985000</td>\n",
       "      <td>11.408000</td>\n",
       "      <td>1008.90000</td>\n",
       "      <td>69.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>133.780000</td>\n",
       "      <td>18.186000</td>\n",
       "      <td>1012.80000</td>\n",
       "      <td>82.266000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>140.895000</td>\n",
       "      <td>23.862500</td>\n",
       "      <td>1016.90000</td>\n",
       "      <td>90.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>174.610000</td>\n",
       "      <td>34.929000</td>\n",
       "      <td>1034.20000</td>\n",
       "      <td>100.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TEY            AT           AP            AH\n",
       "count  15039.000000  15039.000000  15039.00000  15039.000000\n",
       "mean     134.188464     17.764381   1013.19924     79.124174\n",
       "std       15.829717      7.574323      6.41076     13.793439\n",
       "min      100.170000      0.522300    985.85000     30.344000\n",
       "25%      127.985000     11.408000   1008.90000     69.750000\n",
       "50%      133.780000     18.186000   1012.80000     82.266000\n",
       "75%      140.895000     23.862500   1016.90000     90.043500\n",
       "max      174.610000     34.929000   1034.20000    100.200000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_turbines.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEY    0\n",
       "AT     0\n",
       "AP     0\n",
       "AH     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_turbines.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Diving target and features\n",
    "X=df_turbines.iloc[:,1:5]\n",
    "Y=df_turbines.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH\n",
       "0      6.8594  1007.9  96.799\n",
       "1      6.7850  1008.4  97.118\n",
       "2      6.8977  1008.8  95.939\n",
       "3      7.0569  1009.2  95.249\n",
       "4      7.3978  1009.7  95.150\n",
       "...       ...     ...     ...\n",
       "15034  9.0301  1005.6  98.460\n",
       "15035  7.8879  1005.9  99.093\n",
       "15036  7.2647  1006.3  99.496\n",
       "15037  7.0060  1006.8  99.008\n",
       "15038  6.9279  1007.2  97.533\n",
       "\n",
       "[15039 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        114.70\n",
       "1        114.72\n",
       "2        114.71\n",
       "3        114.72\n",
       "4        114.72\n",
       "          ...  \n",
       "15034    111.61\n",
       "15035    111.78\n",
       "15036    110.19\n",
       "15037    110.74\n",
       "15038    111.58\n",
       "Name: TEY, Length: 15039, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=3, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -24682059268096.0000 - accuracy: 0.0000e+00 - val_loss: -24313216368640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -25155342434304.0000 - accuracy: 0.0000e+00 - val_loss: -24777884434432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -25634640232448.0000 - accuracy: 0.0000e+00 - val_loss: -25248527286272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -26119776501760.0000 - accuracy: 0.0000e+00 - val_loss: -25724710813696.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -26611072106496.0000 - accuracy: 0.0000e+00 - val_loss: -26207292751872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -27108623515648.0000 - accuracy: 0.0000e+00 - val_loss: -26695646052352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -27612304900096.0000 - accuracy: 0.0000e+00 - val_loss: -27190213214208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -28122105774080.0000 - accuracy: 0.0000e+00 - val_loss: -27690509795328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -28638072274944.0000 - accuracy: 0.0000e+00 - val_loss: -28197162844160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -29160214888448.0000 - accuracy: 0.0000e+00 - val_loss: -28709501272064.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -29688713969664.0000 - accuracy: 0.0000e+00 - val_loss: -29228389105664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -30223491923968.0000 - accuracy: 0.0000e+00 - val_loss: -29753255919616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -30764613763072.0000 - accuracy: 0.0000e+00 - val_loss: -30284263194624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -31312010280960.0000 - accuracy: 0.0000e+00 - val_loss: -30821488525312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -31865851346944.0000 - accuracy: 0.0000e+00 - val_loss: -31365057740800.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -32426071949312.0000 - accuracy: 0.0000e+00 - val_loss: -31914683531264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -32992800014336.0000 - accuracy: 0.0000e+00 - val_loss: -32471160717312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -33566354309120.0000 - accuracy: 0.0000e+00 - val_loss: -33033941942272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -34146254585856.0000 - accuracy: 0.0000e+00 - val_loss: -33602802810880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -34732857360384.0000 - accuracy: 0.0000e+00 - val_loss: -34178613641216.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -35326282170368.0000 - accuracy: 0.0000e+00 - val_loss: -34760902574080.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -35926067642368.0000 - accuracy: 0.0000e+00 - val_loss: -35349204041728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -36532811464704.0000 - accuracy: 0.0000e+00 - val_loss: -35944736489472.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -37146207453184.0000 - accuracy: 0.0000e+00 - val_loss: -36546279374848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -37766234636288.0000 - accuracy: 0.0000e+00 - val_loss: -37154768027648.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -38393215975424.0000 - accuracy: 0.0000e+00 - val_loss: -37769913040896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -39027189219328.0000 - accuracy: 0.0000e+00 - val_loss: -38391877992448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -39667944652800.0000 - accuracy: 0.0000e+00 - val_loss: -39020402835456.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -40315494858752.0000 - accuracy: 0.0000e+00 - val_loss: -39655487569920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -40969873391616.0000 - accuracy: 0.0000e+00 - val_loss: -40297467740160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -41631394824192.0000 - accuracy: 0.0000e+00 - val_loss: -40946448203776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -42299849441280.0000 - accuracy: 0.0000e+00 - val_loss: -41602043084800.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -42975732170752.0000 - accuracy: 0.0000e+00 - val_loss: -42265191907328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -43658652942336.0000 - accuracy: 0.0000e+00 - val_loss: -42934804152320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -44348410429440.0000 - accuracy: 0.0000e+00 - val_loss: -43611416690688.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -45045654749184.0000 - accuracy: 0.0000e+00 - val_loss: -44295260209152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -45749849030656.0000 - accuracy: 0.0000e+00 - val_loss: -44985726533632.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -46461488201728.0000 - accuracy: 0.0000e+00 - val_loss: -45683998457856.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -47180777783296.0000 - accuracy: 0.0000e+00 - val_loss: -46389304229888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -47906912468992.0000 - accuracy: 0.0000e+00 - val_loss: -47101157310464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -48640395575296.0000 - accuracy: 0.0000e+00 - val_loss: -47820727910400.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -49381751390208.0000 - accuracy: 0.0000e+00 - val_loss: -48547823091712.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -50130342379520.0000 - accuracy: 0.0000e+00 - val_loss: -49281763377152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -50886361481216.0000 - accuracy: 0.0000e+00 - val_loss: -50023215661056.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -51650148433920.0000 - accuracy: 0.0000e+00 - val_loss: -50771924090880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -52420944068608.0000 - accuracy: 0.0000e+00 - val_loss: -51527733477376.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -53199897624576.0000 - accuracy: 0.0000e+00 - val_loss: -52291746922496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -53986602254336.0000 - accuracy: 0.0000e+00 - val_loss: -53062953598976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -54780504309760.0000 - accuracy: 0.0000e+00 - val_loss: -53841127014400.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -55582266490880.0000 - accuracy: 0.0000e+00 - val_loss: -54627445768192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -56391813300224.0000 - accuracy: 0.0000e+00 - val_loss: -55420966141952.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -57208947605504.0000 - accuracy: 0.0000e+00 - val_loss: -56222187257856.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -58034013339648.0000 - accuracy: 0.0000e+00 - val_loss: -57031180419072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -58867287326720.0000 - accuracy: 0.0000e+00 - val_loss: -57848172118016.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -59708182364160.0000 - accuracy: 0.0000e+00 - val_loss: -58672315105280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -60557155631104.0000 - accuracy: 0.0000e+00 - val_loss: -59504779591680.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -61414337150976.0000 - accuracy: 0.0000e+00 - val_loss: -60344810602496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -62279240384512.0000 - accuracy: 0.0000e+00 - val_loss: -61192747876352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -63152079241216.0000 - accuracy: 0.0000e+00 - val_loss: -62048289423360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -64033155710976.0000 - accuracy: 0.0000e+00 - val_loss: -62912009863168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -64922255884288.0000 - accuracy: 0.0000e+00 - val_loss: -63783410073600.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -65819312652288.0000 - accuracy: 0.0000e+00 - val_loss: -64662976593920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -66725143904256.0000 - accuracy: 0.0000e+00 - val_loss: -65550784921600.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -67639032414208.0000 - accuracy: 0.0000e+00 - val_loss: -66446306574336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -68560965599232.0000 - accuracy: 0.0000e+00 - val_loss: -67349952593920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -69491253837824.0000 - accuracy: 0.0000e+00 - val_loss: -68261479710720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -70429595140096.0000 - accuracy: 0.0000e+00 - val_loss: -69181315743744.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -71376358604800.0000 - accuracy: 0.0000e+00 - val_loss: -70109531996160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -72331854610432.0000 - accuracy: 0.0000e+00 - val_loss: -71045662900224.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -73295386902528.0000 - accuracy: 0.0000e+00 - val_loss: -71990127886336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -74267936948224.0000 - accuracy: 0.0000e+00 - val_loss: -72943317024768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -75249211146240.0000 - accuracy: 0.0000e+00 - val_loss: -73905028988928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -76239041724416.0000 - accuracy: 0.0000e+00 - val_loss: -74874601078784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -77236807925760.0000 - accuracy: 0.0000e+00 - val_loss: -75852477890560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -78243340222464.0000 - accuracy: 0.0000e+00 - val_loss: -76838894305280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -79258588282880.0000 - accuracy: 0.0000e+00 - val_loss: -77833548333056.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -80282518552576.0000 - accuracy: 0.0000e+00 - val_loss: -78837119451136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -81315256860672.0000 - accuracy: 0.0000e+00 - val_loss: -79848844296192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -82356366999552.0000 - accuracy: 0.0000e+00 - val_loss: -80869075189760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -83406855602176.0000 - accuracy: 0.0000e+00 - val_loss: -81898743267328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -84466059968512.0000 - accuracy: 0.0000e+00 - val_loss: -82936296636416.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -85534206590976.0000 - accuracy: 0.0000e+00 - val_loss: -83982884536320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -86611362578432.0000 - accuracy: 0.0000e+00 - val_loss: -85038314029056.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -87697502765056.0000 - accuracy: 0.0000e+00 - val_loss: -86102241181696.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -88792794923008.0000 - accuracy: 0.0000e+00 - val_loss: -87175748124672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -89897331326976.0000 - accuracy: 0.0000e+00 - val_loss: -88257786281984.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -91010516385792.0000 - accuracy: 0.0000e+00 - val_loss: -89348271767552.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -92132777918464.0000 - accuracy: 0.0000e+00 - val_loss: -90447892447232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -93264057204736.0000 - accuracy: 0.0000e+00 - val_loss: -91555775905792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -94404010311680.0000 - accuracy: 0.0000e+00 - val_loss: -92672752615424.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -95553509654528.0000 - accuracy: 0.0000e+00 - val_loss: -93798881296384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -96712488124416.0000 - accuracy: 0.0000e+00 - val_loss: -94934371663872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -97881046384640.0000 - accuracy: 0.0000e+00 - val_loss: -96079399878656.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -99059167657984.0000 - accuracy: 0.0000e+00 - val_loss: -97233445847040.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -100246449291264.0000 - accuracy: 0.0000e+00 - val_loss: -98396207579136.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -101442840952832.0000 - accuracy: 0.0000e+00 - val_loss: -99568339386368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -102648736907264.0000 - accuracy: 0.0000e+00 - val_loss: -100749178568704.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -103863365402624.0000 - accuracy: 0.0000e+00 - val_loss: -101939379437568.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -105088303497216.0000 - accuracy: 0.0000e+00 - val_loss: -103139764076544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -106323693797376.0000 - accuracy: 0.0000e+00 - val_loss: -104349049028608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -107567908913152.0000 - accuracy: 0.0000e+00 - val_loss: -105568257703936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -108822391685120.0000 - accuracy: 0.0000e+00 - val_loss: -106796979060736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -110086143868928.0000 - accuracy: 0.0000e+00 - val_loss: -108034550398976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -111359408734208.0000 - accuracy: 0.0000e+00 - val_loss: -109281357594624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -112642085617664.0000 - accuracy: 0.0000e+00 - val_loss: -110537836855296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -113935114043392.0000 - accuracy: 0.0000e+00 - val_loss: -111804273393664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -115237176999936.0000 - accuracy: 0.0000e+00 - val_loss: -113079861903360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -116549717327872.0000 - accuracy: 0.0000e+00 - val_loss: -114364954705920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -117871770337280.0000 - accuracy: 0.0000e+00 - val_loss: -115660566822912.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -119205089247232.0000 - accuracy: 0.0000e+00 - val_loss: -116966186549248.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -120547736289280.0000 - accuracy: 0.0000e+00 - val_loss: -118281134407680.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -121900122505216.0000 - accuracy: 0.0000e+00 - val_loss: -119604470874112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -123262021402624.0000 - accuracy: 0.0000e+00 - val_loss: -120938637033472.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -124633844023296.0000 - accuracy: 0.0000e+00 - val_loss: -122282592698368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -126015590367232.0000 - accuracy: 0.0000e+00 - val_loss: -123635985547264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -127408980099072.0000 - accuracy: 0.0000e+00 - val_loss: -125000493301760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -128812461326336.0000 - accuracy: 0.0000e+00 - val_loss: -126374220136448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -130224717037568.0000 - accuracy: 0.0000e+00 - val_loss: -127758407565312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -131649429831680.0000 - accuracy: 0.0000e+00 - val_loss: -129152652935168.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -133083110047744.0000 - accuracy: 0.0000e+00 - val_loss: -130556662644736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -134527183749120.0000 - accuracy: 0.0000e+00 - val_loss: -131970940010496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -135982330413056.0000 - accuracy: 0.0000e+00 - val_loss: -133395594084352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -137447207862272.0000 - accuracy: 0.0000e+00 - val_loss: -134830121549824.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -138922168418304.0000 - accuracy: 0.0000e+00 - val_loss: -136274279137280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -140408294211584.0000 - accuracy: 0.0000e+00 - val_loss: -137729450967040.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -141905216143360.0000 - accuracy: 0.0000e+00 - val_loss: -139195519598592.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -143412950990848.0000 - accuracy: 0.0000e+00 - val_loss: -140671679725568.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -144930299183104.0000 - accuracy: 0.0000e+00 - val_loss: -142157797130240.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -146458753892352.0000 - accuracy: 0.0000e+00 - val_loss: -143654425460736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -147998382227456.0000 - accuracy: 0.0000e+00 - val_loss: -145161438887936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -149547976228864.0000 - accuracy: 0.0000e+00 - val_loss: -146678485090304.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -151108274094080.0000 - accuracy: 0.0000e+00 - val_loss: -148206788804608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -152679980466176.0000 - accuracy: 0.0000e+00 - val_loss: -149745175625728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -154262222929920.0000 - accuracy: 0.0000e+00 - val_loss: -151294534746112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -155855706128384.0000 - accuracy: 0.0000e+00 - val_loss: -152853792423936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -157459456983040.0000 - accuracy: 0.0000e+00 - val_loss: -154424659935232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -159074113028096.0000 - accuracy: 0.0000e+00 - val_loss: -156005543444480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -160700496347136.0000 - accuracy: 0.0000e+00 - val_loss: -157597818683392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -162336593674240.0000 - accuracy: 0.0000e+00 - val_loss: -159199120064512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -163983680077824.0000 - accuracy: 0.0000e+00 - val_loss: -160812182274048.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -165642896408576.0000 - accuracy: 0.0000e+00 - val_loss: -162437122752512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -167313655463936.0000 - accuracy: 0.0000e+00 - val_loss: -164071324254208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -168994715729920.0000 - accuracy: 0.0000e+00 - val_loss: -165717857009664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/150\n",
      "1008/1008 [==============================] - 4s 3ms/step - loss: -170687100616704.0000 - accuracy: 0.0000e+00 - val_loss: -167374690975744.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -172390994673664.0000 - accuracy: 0.0000e+00 - val_loss: -169042497241088.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -174105525485568.0000 - accuracy: 0.0000e+00 - val_loss: -170720571162624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -175831733239808.0000 - accuracy: 0.0000e+00 - val_loss: -172410624016384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -177569047511040.0000 - accuracy: 0.0000e+00 - val_loss: -174110910971904.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -179317501853696.0000 - accuracy: 0.0000e+00 - val_loss: -175823663398912.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -181079361191936.0000 - accuracy: 0.0000e+00 - val_loss: -177548495421440.0000 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history=model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 1s 2ms/step - loss: -180507543339008.0000 - accuracy: 0.0000e+00\n",
      "accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize training history\n",
    "\n",
    "# list all data in history\n",
    "history.history.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypertuning of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "a = StandardScaler()\n",
    "a.fit(X)\n",
    "X_standardized = a.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.320107e-16</td>\n",
       "      <td>-1.925280e-14</td>\n",
       "      <td>1.844983e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.276462e+00</td>\n",
       "      <td>-4.266288e+00</td>\n",
       "      <td>-3.536594e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.392292e-01</td>\n",
       "      <td>-6.706510e-01</td>\n",
       "      <td>-6.796337e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.566605e-02</td>\n",
       "      <td>-6.227861e-02</td>\n",
       "      <td>2.277844e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.051309e-01</td>\n",
       "      <td>5.772924e-01</td>\n",
       "      <td>7.916582e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.266234e+00</td>\n",
       "      <td>3.275970e+00</td>\n",
       "      <td>1.528011e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2\n",
       "count  1.503900e+04  1.503900e+04  1.503900e+04\n",
       "mean  -2.320107e-16 -1.925280e-14  1.844983e-16\n",
       "std    1.000033e+00  1.000033e+00  1.000033e+00\n",
       "min   -2.276462e+00 -4.266288e+00 -3.536594e+00\n",
       "25%   -8.392292e-01 -6.706510e-01 -6.796337e-01\n",
       "50%    5.566605e-02 -6.227861e-02  2.277844e-01\n",
       "75%    8.051309e-01  5.772924e-01  7.916582e-01\n",
       "max    2.266234e+00  3.275970e+00  1.528011e+00"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_standardized).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=3, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    \n",
    "    adam=Adam(learning_rate=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12424\\120257800.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 1/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time=  18.8s\n",
      "[CV 2/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 2/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time=  20.7s\n",
      "[CV 3/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 3/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time=  19.4s\n",
      "[CV 4/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 4/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time=  19.5s\n",
      "[CV 5/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 5/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time=  18.6s\n",
      "[CV 1/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 1/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 1.5min\n",
      "[CV 2/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 2/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 1.5min\n",
      "[CV 3/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 3/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 1.5min\n",
      "[CV 4/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 4/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 1.5min\n",
      "[CV 5/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 5/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 1.5min\n",
      "[CV 1/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 1/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time= 2.9min\n",
      "[CV 2/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 2/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time= 2.9min\n",
      "[CV 3/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 3/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time= 2.9min\n",
      "[CV 4/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 4/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time= 2.9min\n",
      "[CV 5/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 5/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time= 3.0min\n",
      "[CV 1/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 1/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=  10.3s\n",
      "[CV 2/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 2/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=   9.6s\n",
      "[CV 3/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 3/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=  10.0s\n",
      "[CV 4/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 4/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=  10.3s\n",
      "[CV 5/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 5/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=   9.5s\n",
      "[CV 1/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 1/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time=  45.2s\n",
      "[CV 2/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 2/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time=  45.9s\n",
      "[CV 3/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 3/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time=  46.8s\n",
      "[CV 4/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 4/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time=  45.0s\n",
      "[CV 5/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 5/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time=  44.9s\n",
      "[CV 1/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 1/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 1.5min\n",
      "[CV 2/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 2/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 1.5min\n",
      "[CV 3/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 3/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 1.6min\n",
      "[CV 4/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 4/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 1.5min\n",
      "[CV 5/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 5/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 1.5min\n",
      "[CV 1/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 1/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time=   5.7s\n",
      "[CV 2/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 2/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time=   5.7s\n",
      "[CV 3/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 3/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time=   5.3s\n",
      "[CV 4/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 4/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time=   5.2s\n",
      "[CV 5/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 5/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time=   5.6s\n",
      "[CV 1/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 1/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time=  23.0s\n",
      "[CV 2/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 2/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time=  23.3s\n",
      "[CV 3/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 3/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time=  23.4s\n",
      "[CV 4/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 4/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time=  23.6s\n",
      "[CV 5/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 5/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time=  23.5s\n",
      "[CV 1/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 1/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time=  46.4s\n",
      "[CV 2/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 2/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time=  45.5s\n",
      "[CV 3/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 3/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time=  45.8s\n",
      "[CV 4/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 4/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time=  45.0s\n",
      "[CV 5/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 5/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time=  45.7s\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "# Define the grid search parameters\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'batch_size': 10, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.0,0.0 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.0,0.0 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.0,0.0 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.0,0.0 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.0,0.0 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "def create_model(learning_rate,dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 3,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4,input_dim = 3,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12424\\384741517.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 1/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=   5.6s\n",
      "[CV 2/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=   5.3s\n",
      "[CV 3/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=   5.7s\n",
      "[CV 4/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=   5.4s\n",
      "[CV 5/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=   5.4s\n",
      "[CV 1/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=   5.7s\n",
      "[CV 2/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=   5.6s\n",
      "[CV 3/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=   5.9s\n",
      "[CV 4/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=   5.9s\n",
      "[CV 5/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=   5.4s\n",
      "[CV 1/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=   5.9s\n",
      "[CV 2/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=   5.5s\n",
      "[CV 3/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=   5.4s\n",
      "[CV 4/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=   5.8s\n",
      "[CV 5/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=   5.7s\n",
      "[CV 1/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=   6.1s\n",
      "[CV 2/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=   6.7s\n",
      "[CV 3/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=   5.8s\n",
      "[CV 4/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=   6.1s\n",
      "[CV 5/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=   6.0s\n",
      "[CV 1/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=   6.0s\n",
      "[CV 2/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=   6.3s\n",
      "[CV 3/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=   5.7s\n",
      "[CV 4/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=   6.3s\n",
      "[CV 5/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=   6.4s\n",
      "[CV 1/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=   5.7s\n",
      "[CV 2/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=   6.6s\n",
      "[CV 3/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=   6.2s\n",
      "[CV 4/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=   7.0s\n",
      "[CV 5/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=   6.9s\n",
      "[CV 1/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=   6.0s\n",
      "[CV 2/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=   6.2s\n",
      "[CV 3/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=   5.9s\n",
      "[CV 4/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=   5.9s\n",
      "[CV 5/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=   6.9s\n",
      "[CV 1/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=   5.8s\n",
      "[CV 2/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=   6.9s\n",
      "[CV 3/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=   5.8s\n",
      "[CV 4/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=   6.1s\n",
      "[CV 5/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=   6.3s\n",
      "[CV 1/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=   6.2s\n",
      "[CV 2/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=   6.3s\n",
      "[CV 3/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=   5.8s\n",
      "[CV 4/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=   6.1s\n",
      "[CV 5/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=   6.4s\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning of Hyperparameters:- Activation Function and Kernel Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 3,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4,input_dim = 3,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12424\\2864657069.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 1/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=   7.7s\n",
      "[CV 2/5; 1/12] START activation_function=softmax, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=   8.9s\n",
      "[CV 3/5; 1/12] START activation_function=softmax, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=   8.5s\n",
      "[CV 4/5; 1/12] START activation_function=softmax, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=   7.0s\n",
      "[CV 5/5; 1/12] START activation_function=softmax, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=   6.4s\n",
      "[CV 1/5; 2/12] START activation_function=softmax, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/12] END activation_function=softmax, init=normal;, score=0.000 total time=   6.8s\n",
      "[CV 2/5; 2/12] START activation_function=softmax, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/12] END activation_function=softmax, init=normal;, score=0.000 total time=   6.4s\n",
      "[CV 3/5; 2/12] START activation_function=softmax, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/12] END activation_function=softmax, init=normal;, score=0.000 total time=   8.1s\n",
      "[CV 4/5; 2/12] START activation_function=softmax, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 2/12] END activation_function=softmax, init=normal;, score=0.000 total time=   6.7s\n",
      "[CV 5/5; 2/12] START activation_function=softmax, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/12] END activation_function=softmax, init=normal;, score=0.000 total time=   6.5s\n",
      "[CV 1/5; 3/12] START activation_function=softmax, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=   6.2s\n",
      "[CV 2/5; 3/12] START activation_function=softmax, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=   6.3s\n",
      "[CV 3/5; 3/12] START activation_function=softmax, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=   6.7s\n",
      "[CV 4/5; 3/12] START activation_function=softmax, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=   6.3s\n",
      "[CV 5/5; 3/12] START activation_function=softmax, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=   7.6s\n",
      "[CV 1/5; 4/12] START activation_function=relu, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/12] END activation_function=relu, init=uniform;, score=0.000 total time=   6.7s\n",
      "[CV 2/5; 4/12] START activation_function=relu, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/12] END activation_function=relu, init=uniform;, score=0.000 total time=   7.0s\n",
      "[CV 3/5; 4/12] START activation_function=relu, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/12] END activation_function=relu, init=uniform;, score=0.000 total time=   6.5s\n",
      "[CV 4/5; 4/12] START activation_function=relu, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/12] END activation_function=relu, init=uniform;, score=0.000 total time=   6.4s\n",
      "[CV 5/5; 4/12] START activation_function=relu, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 4/12] END activation_function=relu, init=uniform;, score=0.000 total time=   6.5s\n",
      "[CV 1/5; 5/12] START activation_function=relu, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/12] END activation_function=relu, init=normal;, score=0.000 total time=   6.4s\n",
      "[CV 2/5; 5/12] START activation_function=relu, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/12] END activation_function=relu, init=normal;, score=0.000 total time=   6.7s\n",
      "[CV 3/5; 5/12] START activation_function=relu, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/12] END activation_function=relu, init=normal;, score=0.000 total time=   7.2s\n",
      "[CV 4/5; 5/12] START activation_function=relu, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 5/12] END activation_function=relu, init=normal;, score=0.000 total time=   6.6s\n",
      "[CV 5/5; 5/12] START activation_function=relu, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/12] END activation_function=relu, init=normal;, score=0.000 total time=   6.7s\n",
      "[CV 1/5; 6/12] START activation_function=relu, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=   8.0s\n",
      "[CV 2/5; 6/12] START activation_function=relu, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=   8.6s\n",
      "[CV 3/5; 6/12] START activation_function=relu, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=   6.4s\n",
      "[CV 4/5; 6/12] START activation_function=relu, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=   6.8s\n",
      "[CV 5/5; 6/12] START activation_function=relu, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=   7.0s\n",
      "[CV 1/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 7/12] END activation_function=tanh, init=uniform;, score=0.000 total time=   8.1s\n",
      "[CV 2/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 7/12] END activation_function=tanh, init=uniform;, score=0.000 total time=   7.0s\n",
      "[CV 3/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 7/12] END activation_function=tanh, init=uniform;, score=0.000 total time=   6.8s\n",
      "[CV 4/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 7/12] END activation_function=tanh, init=uniform;, score=0.000 total time=   6.6s\n",
      "[CV 5/5; 7/12] START activation_function=tanh, init=uniform.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 7/12] END activation_function=tanh, init=uniform;, score=0.000 total time=   7.1s\n",
      "[CV 1/5; 8/12] START activation_function=tanh, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 8/12] END activation_function=tanh, init=normal;, score=0.000 total time=   8.4s\n",
      "[CV 2/5; 8/12] START activation_function=tanh, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 8/12] END activation_function=tanh, init=normal;, score=0.000 total time=   6.7s\n",
      "[CV 3/5; 8/12] START activation_function=tanh, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/12] END activation_function=tanh, init=normal;, score=0.000 total time=   6.9s\n",
      "[CV 4/5; 8/12] START activation_function=tanh, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 8/12] END activation_function=tanh, init=normal;, score=0.000 total time=   6.8s\n",
      "[CV 5/5; 8/12] START activation_function=tanh, init=normal......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 8/12] END activation_function=tanh, init=normal;, score=0.000 total time=   6.7s\n",
      "[CV 1/5; 9/12] START activation_function=tanh, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=   6.3s\n",
      "[CV 2/5; 9/12] START activation_function=tanh, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=   6.6s\n",
      "[CV 3/5; 9/12] START activation_function=tanh, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=   6.8s\n",
      "[CV 4/5; 9/12] START activation_function=tanh, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=   6.4s\n",
      "[CV 5/5; 9/12] START activation_function=tanh, init=zero........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=   6.6s\n",
      "[CV 1/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 10/12] END activation_function=linear, init=uniform;, score=0.000 total time=   5.9s\n",
      "[CV 2/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 10/12] END activation_function=linear, init=uniform;, score=0.000 total time=   7.0s\n",
      "[CV 3/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 10/12] END activation_function=linear, init=uniform;, score=0.000 total time=   6.2s\n",
      "[CV 4/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 10/12] END activation_function=linear, init=uniform;, score=0.000 total time=   6.7s\n",
      "[CV 5/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 10/12] END activation_function=linear, init=uniform;, score=0.000 total time=   6.6s\n",
      "[CV 1/5; 11/12] START activation_function=linear, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/12] END activation_function=linear, init=normal;, score=0.000 total time=   6.0s\n",
      "[CV 2/5; 11/12] START activation_function=linear, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 11/12] END activation_function=linear, init=normal;, score=0.000 total time=   6.6s\n",
      "[CV 3/5; 11/12] START activation_function=linear, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 11/12] END activation_function=linear, init=normal;, score=0.000 total time=   5.8s\n",
      "[CV 4/5; 11/12] START activation_function=linear, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 11/12] END activation_function=linear, init=normal;, score=0.000 total time=   6.2s\n",
      "[CV 5/5; 11/12] START activation_function=linear, init=normal...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 11/12] END activation_function=linear, init=normal;, score=0.000 total time=   6.3s\n",
      "[CV 1/5; 12/12] START activation_function=linear, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=   5.8s\n",
      "[CV 2/5; 12/12] START activation_function=linear, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=   6.7s\n",
      "[CV 3/5; 12/12] START activation_function=linear, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=   5.9s\n",
      "[CV 4/5; 12/12] START activation_function=linear, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=   6.3s\n",
      "[CV 5/5; 12/12] START activation_function=linear, init=zero.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=   6.6s\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(activation_function = activation_function,init = init)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'activation_function': 'softmax', 'init': 'uniform'}\n",
      "0.0,0.0 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
      "0.0,0.0 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
      "0.0,0.0 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
      "0.0,0.0 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
      "0.0,0.0 with: {'activation_function': 'relu', 'init': 'normal'}\n",
      "0.0,0.0 with: {'activation_function': 'relu', 'init': 'zero'}\n",
      "0.0,0.0 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
      "0.0,0.0 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.0,0.0 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
      "0.0,0.0 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.0,0.0 with: {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.0,0.0 with: {'activation_function': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning of Hyperparameter :-Number of Neurons in activation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 3,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12424\\4114978605.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 1/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.000 total time=   6.4s\n",
      "[CV 2/5; 1/9] START neuron1=4, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.000 total time=   7.0s\n",
      "[CV 3/5; 1/9] START neuron1=4, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.000 total time=   6.2s\n",
      "[CV 4/5; 1/9] START neuron1=4, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.000 total time=   7.1s\n",
      "[CV 5/5; 1/9] START neuron1=4, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.000 total time=   6.3s\n",
      "[CV 1/5; 2/9] START neuron1=4, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.000 total time=   6.1s\n",
      "[CV 2/5; 2/9] START neuron1=4, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.000 total time=   6.4s\n",
      "[CV 3/5; 2/9] START neuron1=4, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.000 total time=   5.7s\n",
      "[CV 4/5; 2/9] START neuron1=4, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.000 total time=   6.5s\n",
      "[CV 5/5; 2/9] START neuron1=4, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.000 total time=   5.9s\n",
      "[CV 1/5; 3/9] START neuron1=4, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.000 total time=   6.0s\n",
      "[CV 2/5; 3/9] START neuron1=4, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.000 total time=   6.6s\n",
      "[CV 3/5; 3/9] START neuron1=4, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.000 total time=   6.0s\n",
      "[CV 4/5; 3/9] START neuron1=4, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.000 total time=   6.8s\n",
      "[CV 5/5; 3/9] START neuron1=4, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.000 total time=   5.9s\n",
      "[CV 1/5; 4/9] START neuron1=8, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.000 total time=   6.3s\n",
      "[CV 2/5; 4/9] START neuron1=8, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.000 total time=   7.0s\n",
      "[CV 3/5; 4/9] START neuron1=8, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.000 total time=   6.8s\n",
      "[CV 4/5; 4/9] START neuron1=8, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.000 total time=   6.5s\n",
      "[CV 5/5; 4/9] START neuron1=8, neuron2=2........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.000 total time=   5.8s\n",
      "[CV 1/5; 5/9] START neuron1=8, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.000 total time=   5.8s\n",
      "[CV 2/5; 5/9] START neuron1=8, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.000 total time=   6.5s\n",
      "[CV 3/5; 5/9] START neuron1=8, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.000 total time=   5.9s\n",
      "[CV 4/5; 5/9] START neuron1=8, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.000 total time=   6.7s\n",
      "[CV 5/5; 5/9] START neuron1=8, neuron2=4........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.000 total time=   6.1s\n",
      "[CV 1/5; 6/9] START neuron1=8, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.000 total time=   5.9s\n",
      "[CV 2/5; 6/9] START neuron1=8, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.000 total time=   6.6s\n",
      "[CV 3/5; 6/9] START neuron1=8, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.000 total time=   5.8s\n",
      "[CV 4/5; 6/9] START neuron1=8, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.000 total time=   6.4s\n",
      "[CV 5/5; 6/9] START neuron1=8, neuron2=8........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.000 total time=   6.0s\n",
      "[CV 1/5; 7/9] START neuron1=16, neuron2=2.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.000 total time=   5.8s\n",
      "[CV 2/5; 7/9] START neuron1=16, neuron2=2.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.000 total time=   6.8s\n",
      "[CV 3/5; 7/9] START neuron1=16, neuron2=2.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.000 total time=   6.2s\n",
      "[CV 4/5; 7/9] START neuron1=16, neuron2=2.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.000 total time=   6.4s\n",
      "[CV 5/5; 7/9] START neuron1=16, neuron2=2.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.000 total time=   6.2s\n",
      "[CV 1/5; 8/9] START neuron1=16, neuron2=4.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.000 total time=   5.9s\n",
      "[CV 2/5; 8/9] START neuron1=16, neuron2=4.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.000 total time=   6.4s\n",
      "[CV 3/5; 8/9] START neuron1=16, neuron2=4.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.000 total time=   5.8s\n",
      "[CV 4/5; 8/9] START neuron1=16, neuron2=4.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.000 total time=   7.2s\n",
      "[CV 5/5; 8/9] START neuron1=16, neuron2=4.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.000 total time=   6.4s\n",
      "[CV 1/5; 9/9] START neuron1=16, neuron2=8.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.000 total time=   6.4s\n",
      "[CV 2/5; 9/9] START neuron1=16, neuron2=8.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.000 total time=   7.4s\n",
      "[CV 3/5; 9/9] START neuron1=16, neuron2=8.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.000 total time=   6.6s\n",
      "[CV 4/5; 9/9] START neuron1=16, neuron2=8.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.000 total time=   6.9s\n",
      "[CV 5/5; 9/9] START neuron1=16, neuron2=8.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.000 total time=   5.8s\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'neuron1': 4, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model with optimum values of Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16,input_dim = 3,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(8,input_dim = 3,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'linear'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12424\\792720346.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 1s 1ms/step\n",
      "0.00013298756566261055\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 100)\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "model.fit(X_standardized,Y)\n",
    "\n",
    "# Predicting using trained model\n",
    "\n",
    "y_predict = model.predict(X_standardized)\n",
    "\n",
    "# Printing the metrics\n",
    "print(accuracy_score(Y.round(),y_predict.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
